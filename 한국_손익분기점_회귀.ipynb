{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_fin = pd.read_csv('전처리_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dist_rank</th>\n",
       "      <th>genre_rank</th>\n",
       "      <th>direct_rank</th>\n",
       "      <th>네이버_기대지수</th>\n",
       "      <th>star_buzz</th>\n",
       "      <th>movie_buzz_naver</th>\n",
       "      <th>google_trend</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>67</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>1629</td>\n",
       "      <td>22</td>\n",
       "      <td>773.0</td>\n",
       "      <td>723414.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>67</td>\n",
       "      <td>3838.0</td>\n",
       "      <td>581</td>\n",
       "      <td>19</td>\n",
       "      <td>387.0</td>\n",
       "      <td>351276.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>41</td>\n",
       "      <td>494.0</td>\n",
       "      <td>943</td>\n",
       "      <td>30</td>\n",
       "      <td>616.0</td>\n",
       "      <td>336822.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>94</td>\n",
       "      <td>162.0</td>\n",
       "      <td>111</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7443.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>67</td>\n",
       "      <td>800.0</td>\n",
       "      <td>335</td>\n",
       "      <td>5</td>\n",
       "      <td>1674.0</td>\n",
       "      <td>24823.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>13693.0</td>\n",
       "      <td>1987</td>\n",
       "      <td>219</td>\n",
       "      <td>947.0</td>\n",
       "      <td>7759473.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>72</td>\n",
       "      <td>10731.0</td>\n",
       "      <td>1196</td>\n",
       "      <td>124</td>\n",
       "      <td>886.0</td>\n",
       "      <td>955175.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4941.0</td>\n",
       "      <td>1413</td>\n",
       "      <td>379</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8646758.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>100</td>\n",
       "      <td>247.0</td>\n",
       "      <td>147</td>\n",
       "      <td>25</td>\n",
       "      <td>459.0</td>\n",
       "      <td>1660.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>67</td>\n",
       "      <td>13877.0</td>\n",
       "      <td>1830</td>\n",
       "      <td>61</td>\n",
       "      <td>2593.0</td>\n",
       "      <td>7231638.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>575 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     dist_rank  genre_rank  direct_rank  네이버_기대지수  star_buzz  \\\n",
       "0            4           5           67    1274.0       1629   \n",
       "1            8          13           67    3838.0        581   \n",
       "2            2          13           41     494.0        943   \n",
       "3            8          13           94     162.0        111   \n",
       "4            3          13           67     800.0        335   \n",
       "..         ...         ...          ...       ...        ...   \n",
       "570          3          13            5   13693.0       1987   \n",
       "571          2          13           72   10731.0       1196   \n",
       "572          4           1            5    4941.0       1413   \n",
       "573          7           8          100     247.0        147   \n",
       "574          3          13           67   13877.0       1830   \n",
       "\n",
       "     movie_buzz_naver  google_trend     Target  \n",
       "0                  22         773.0   723414.0  \n",
       "1                  19         387.0   351276.0  \n",
       "2                  30         616.0   336822.0  \n",
       "3                   6           0.0     7443.0  \n",
       "4                   5        1674.0    24823.0  \n",
       "..                ...           ...        ...  \n",
       "570               219         947.0  7759473.0  \n",
       "571               124         886.0   955175.0  \n",
       "572               379           0.0  8646758.0  \n",
       "573                25         459.0     1660.0  \n",
       "574                61        2593.0  7231638.0  \n",
       "\n",
       "[575 rows x 8 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_fin['Target']\n",
    "x = df_fin.drop('Target', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정규화, 정규화하는 것이 더 좋은 결과를 낳음\n",
    "from sklearn.preprocessing import StandardScaler\n",
    " \n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    " \n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-*- coding: utf-8 -*-\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout, Dense\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 딥러닝 모델 선언\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim=7, activation='elu'))  # 입력층\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(8, activation='elu'))      # 은닉층1 \n",
    "#model.add(BatchNormalization())\n",
    "#model.add(Dropout(0.2))\n",
    "#model.add(Dense(64, activation='elu'))      # 은닉층1\n",
    "#model.add(BatchNormalization())\n",
    "#model.add(Dense(32, activation='elu'))\n",
    "#model.add(BatchNormalization())\n",
    "#model.add(Dense(16, activation='elu'))\n",
    "#model.add(BatchNormalization())\n",
    "#model.add(Dense(16, activation='elu'))\n",
    "#model.add(BatchNormalization())\n",
    "#model.add(Dense(8, activation='elu'))\n",
    "#model.add(BatchNormalization())\n",
    "#model.add(Dense(8, activation='elu'))\n",
    "#model.add(BatchNormalization())\n",
    "#model.add(Dense(4, activation='elu'))\n",
    "#model.add(Dense(4, activation='elu'))\n",
    "model.add(Dense(1))# 출력층\n",
    "# 선형 회귀는 마지막에 참과 거짓을 구분할 필요가 없음. 출력층에 활성화 함수를 지정할 필요도 없음\n",
    "\n",
    "model.compile(loss='mean_absolute_error',\n",
    "              optimizer='Nadam', \n",
    "              metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장 폴더 만들기\n",
    "MODEL_DIR = './model/'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)\n",
    "\n",
    "modelpath = \"./model/{epoch:02d}-{val_loss:.4f}.hdf5\"\n",
    "\n",
    "# 모델 업데이트 및 저장\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_mae', verbose=0, save_best_only=True, mode='min')\n",
    "# 콜백함수\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_mae', factor=0.2, patience=20, mode='min')\n",
    "\n",
    "# 학습 자동 중단 설정\n",
    "early_stopping_callback = EarlyStopping(monitor='val_mae', patience=40, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "5/5 [==============================] - 1s 31ms/step - loss: 1360789.3750 - mae: 1360789.3750 - val_loss: 1439113.7500 - val_mae: 1439113.7500 - lr: 0.0010\n",
      "Epoch 2/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1360750.2500 - mae: 1360750.2500 - val_loss: 1439024.8750 - val_mae: 1439024.8750 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1360555.0000 - mae: 1360555.0000 - val_loss: 1438916.0000 - val_mae: 1438916.0000 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1360584.2500 - mae: 1360584.2500 - val_loss: 1438807.0000 - val_mae: 1438807.0000 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1360456.5000 - mae: 1360456.5000 - val_loss: 1438690.6250 - val_mae: 1438690.6250 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1360449.5000 - mae: 1360449.5000 - val_loss: 1438565.6250 - val_mae: 1438565.6250 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1360127.3750 - mae: 1360127.3750 - val_loss: 1438432.3750 - val_mae: 1438432.3750 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1360026.7500 - mae: 1360026.7500 - val_loss: 1438279.8750 - val_mae: 1438279.8750 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1359973.8750 - mae: 1359973.8750 - val_loss: 1438128.7500 - val_mae: 1438128.7500 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1359927.3750 - mae: 1359927.3750 - val_loss: 1437960.8750 - val_mae: 1437960.8750 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1359570.5000 - mae: 1359570.5000 - val_loss: 1437778.0000 - val_mae: 1437778.0000 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1359626.8750 - mae: 1359626.8750 - val_loss: 1437600.0000 - val_mae: 1437600.0000 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1359122.5000 - mae: 1359122.5000 - val_loss: 1437382.2500 - val_mae: 1437382.2500 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1358955.7500 - mae: 1358955.7500 - val_loss: 1437148.0000 - val_mae: 1437148.0000 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1358896.0000 - mae: 1358896.0000 - val_loss: 1436901.0000 - val_mae: 1436901.0000 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1358924.3750 - mae: 1358924.3750 - val_loss: 1436649.0000 - val_mae: 1436649.0000 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1358337.2500 - mae: 1358337.2500 - val_loss: 1436356.3750 - val_mae: 1436356.3750 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1358203.6250 - mae: 1358203.6250 - val_loss: 1436048.8750 - val_mae: 1436048.8750 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1357667.1250 - mae: 1357667.1250 - val_loss: 1435696.8750 - val_mae: 1435696.8750 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1357605.2500 - mae: 1357605.2500 - val_loss: 1435355.5000 - val_mae: 1435355.5000 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1357325.1250 - mae: 1357325.1250 - val_loss: 1434968.3750 - val_mae: 1434968.3750 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1357235.2500 - mae: 1357235.2500 - val_loss: 1434586.6250 - val_mae: 1434586.6250 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1356729.2500 - mae: 1356729.2500 - val_loss: 1434176.7500 - val_mae: 1434176.7500 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1356424.2500 - mae: 1356424.2500 - val_loss: 1433749.5000 - val_mae: 1433749.5000 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1355781.7500 - mae: 1355781.7500 - val_loss: 1433271.5000 - val_mae: 1433271.5000 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1355815.2500 - mae: 1355815.2500 - val_loss: 1432790.3750 - val_mae: 1432790.3750 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1355021.5000 - mae: 1355021.5000 - val_loss: 1432291.7500 - val_mae: 1432291.7500 - lr: 0.0010\n",
      "Epoch 28/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1354460.1250 - mae: 1354460.1250 - val_loss: 1431738.0000 - val_mae: 1431738.0000 - lr: 0.0010\n",
      "Epoch 29/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1354094.7500 - mae: 1354094.7500 - val_loss: 1431201.6250 - val_mae: 1431201.6250 - lr: 0.0010\n",
      "Epoch 30/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1353742.7500 - mae: 1353742.7500 - val_loss: 1430625.0000 - val_mae: 1430625.0000 - lr: 0.0010\n",
      "Epoch 31/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1352539.6250 - mae: 1352539.6250 - val_loss: 1429962.8750 - val_mae: 1429962.8750 - lr: 0.0010\n",
      "Epoch 32/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1352306.1250 - mae: 1352306.1250 - val_loss: 1429315.5000 - val_mae: 1429315.5000 - lr: 0.0010\n",
      "Epoch 33/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1352323.3750 - mae: 1352323.3750 - val_loss: 1428652.8750 - val_mae: 1428652.8750 - lr: 0.0010\n",
      "Epoch 34/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1351327.0000 - mae: 1351327.0000 - val_loss: 1427934.1250 - val_mae: 1427934.1250 - lr: 0.0010\n",
      "Epoch 35/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1351032.1250 - mae: 1351032.1250 - val_loss: 1427213.0000 - val_mae: 1427213.0000 - lr: 0.0010\n",
      "Epoch 36/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1349914.6250 - mae: 1349914.6250 - val_loss: 1426370.1250 - val_mae: 1426370.1250 - lr: 0.0010\n",
      "Epoch 37/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1350073.6250 - mae: 1350073.6250 - val_loss: 1425557.1250 - val_mae: 1425557.1250 - lr: 0.0010\n",
      "Epoch 38/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1347863.3750 - mae: 1347863.3750 - val_loss: 1424690.8750 - val_mae: 1424690.8750 - lr: 0.0010\n",
      "Epoch 39/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1347347.8750 - mae: 1347347.8750 - val_loss: 1423820.7500 - val_mae: 1423820.7500 - lr: 0.0010\n",
      "Epoch 40/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1347415.5000 - mae: 1347415.5000 - val_loss: 1422920.1250 - val_mae: 1422920.1250 - lr: 0.0010\n",
      "Epoch 41/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1346216.5000 - mae: 1346216.5000 - val_loss: 1421919.2500 - val_mae: 1421919.2500 - lr: 0.0010\n",
      "Epoch 42/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1344740.7500 - mae: 1344740.7500 - val_loss: 1420843.8750 - val_mae: 1420843.8750 - lr: 0.0010\n",
      "Epoch 43/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1344690.1250 - mae: 1344690.1250 - val_loss: 1419804.8750 - val_mae: 1419804.8750 - lr: 0.0010\n",
      "Epoch 44/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1341917.2500 - mae: 1341917.2500 - val_loss: 1418646.2500 - val_mae: 1418646.2500 - lr: 0.0010\n",
      "Epoch 45/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1342224.0000 - mae: 1342224.0000 - val_loss: 1417501.3750 - val_mae: 1417501.3750 - lr: 0.0010\n",
      "Epoch 46/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1339528.8750 - mae: 1339528.8750 - val_loss: 1416244.0000 - val_mae: 1416244.0000 - lr: 0.0010\n",
      "Epoch 47/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1340014.5000 - mae: 1340014.5000 - val_loss: 1415007.5000 - val_mae: 1415007.5000 - lr: 0.0010\n",
      "Epoch 48/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1337487.2500 - mae: 1337487.2500 - val_loss: 1413681.2500 - val_mae: 1413681.2500 - lr: 0.0010\n",
      "Epoch 49/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 11ms/step - loss: 1337539.7500 - mae: 1337539.7500 - val_loss: 1412314.5000 - val_mae: 1412314.5000 - lr: 0.0010\n",
      "Epoch 50/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1336322.6250 - mae: 1336322.6250 - val_loss: 1410925.5000 - val_mae: 1410925.5000 - lr: 0.0010\n",
      "Epoch 51/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1334468.6250 - mae: 1334468.6250 - val_loss: 1409329.2500 - val_mae: 1409329.2500 - lr: 0.0010\n",
      "Epoch 52/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1333299.5000 - mae: 1333299.5000 - val_loss: 1407732.5000 - val_mae: 1407732.5000 - lr: 0.0010\n",
      "Epoch 53/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1332187.0000 - mae: 1332187.0000 - val_loss: 1406156.3750 - val_mae: 1406156.3750 - lr: 0.0010\n",
      "Epoch 54/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1330793.1250 - mae: 1330793.1250 - val_loss: 1404427.3750 - val_mae: 1404427.3750 - lr: 0.0010\n",
      "Epoch 55/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1325633.5000 - mae: 1325633.5000 - val_loss: 1402652.0000 - val_mae: 1402652.0000 - lr: 0.0010\n",
      "Epoch 56/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1327568.7500 - mae: 1327568.7500 - val_loss: 1400804.3750 - val_mae: 1400804.3750 - lr: 0.0010\n",
      "Epoch 57/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1327614.6250 - mae: 1327614.6250 - val_loss: 1399010.8750 - val_mae: 1399010.8750 - lr: 0.0010\n",
      "Epoch 58/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1323727.2500 - mae: 1323727.1250 - val_loss: 1397092.7500 - val_mae: 1397092.7500 - lr: 0.0010\n",
      "Epoch 59/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1322535.0000 - mae: 1322535.0000 - val_loss: 1395118.2500 - val_mae: 1395118.2500 - lr: 0.0010\n",
      "Epoch 60/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1321169.3750 - mae: 1321169.3750 - val_loss: 1393052.2500 - val_mae: 1393052.2500 - lr: 0.0010\n",
      "Epoch 61/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1321706.6250 - mae: 1321706.6250 - val_loss: 1390946.8750 - val_mae: 1390946.8750 - lr: 0.0010\n",
      "Epoch 62/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1315523.2500 - mae: 1315523.2500 - val_loss: 1388631.0000 - val_mae: 1388631.0000 - lr: 0.0010\n",
      "Epoch 63/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1313575.3750 - mae: 1313575.2500 - val_loss: 1386262.7500 - val_mae: 1386262.7500 - lr: 0.0010\n",
      "Epoch 64/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1313928.6250 - mae: 1313928.6250 - val_loss: 1384060.5000 - val_mae: 1384060.5000 - lr: 0.0010\n",
      "Epoch 65/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308695.6250 - mae: 1308695.6250 - val_loss: 1381734.3750 - val_mae: 1381734.3750 - lr: 0.0010\n",
      "Epoch 66/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1310397.0000 - mae: 1310397.0000 - val_loss: 1379418.5000 - val_mae: 1379418.5000 - lr: 0.0010\n",
      "Epoch 67/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1309424.7500 - mae: 1309424.7500 - val_loss: 1377049.3750 - val_mae: 1377049.3750 - lr: 0.0010\n",
      "Epoch 68/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1304196.1250 - mae: 1304196.1250 - val_loss: 1374552.3750 - val_mae: 1374552.3750 - lr: 0.0010\n",
      "Epoch 69/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1300135.6250 - mae: 1300135.6250 - val_loss: 1371918.5000 - val_mae: 1371918.5000 - lr: 0.0010\n",
      "Epoch 70/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1301396.0000 - mae: 1301396.0000 - val_loss: 1369290.6250 - val_mae: 1369290.6250 - lr: 0.0010\n",
      "Epoch 71/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1297093.1250 - mae: 1297093.1250 - val_loss: 1366715.7500 - val_mae: 1366715.7500 - lr: 0.0010\n",
      "Epoch 72/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1297220.5000 - mae: 1297220.5000 - val_loss: 1364430.5000 - val_mae: 1364430.5000 - lr: 0.0010\n",
      "Epoch 73/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1297722.1250 - mae: 1297722.1250 - val_loss: 1362068.5000 - val_mae: 1362068.5000 - lr: 0.0010\n",
      "Epoch 74/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1289775.5000 - mae: 1289775.5000 - val_loss: 1359628.5000 - val_mae: 1359628.7500 - lr: 0.0010\n",
      "Epoch 75/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1295540.0000 - mae: 1295540.0000 - val_loss: 1357416.8750 - val_mae: 1357416.8750 - lr: 0.0010\n",
      "Epoch 76/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1287492.5000 - mae: 1287492.5000 - val_loss: 1354872.8750 - val_mae: 1354872.8750 - lr: 0.0010\n",
      "Epoch 77/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1288657.6250 - mae: 1288657.6250 - val_loss: 1352459.3750 - val_mae: 1352459.3750 - lr: 0.0010\n",
      "Epoch 78/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1279436.0000 - mae: 1279436.0000 - val_loss: 1349906.6250 - val_mae: 1349906.6250 - lr: 0.0010\n",
      "Epoch 79/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1280629.8750 - mae: 1280629.8750 - val_loss: 1347447.0000 - val_mae: 1347447.0000 - lr: 0.0010\n",
      "Epoch 80/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1274797.8750 - mae: 1274797.8750 - val_loss: 1344887.6250 - val_mae: 1344887.6250 - lr: 0.0010\n",
      "Epoch 81/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1281659.3750 - mae: 1281659.3750 - val_loss: 1342337.6250 - val_mae: 1342337.5000 - lr: 0.0010\n",
      "Epoch 82/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1275418.2500 - mae: 1275418.2500 - val_loss: 1339858.3750 - val_mae: 1339858.3750 - lr: 0.0010\n",
      "Epoch 83/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1277167.2500 - mae: 1277167.2500 - val_loss: 1337583.6250 - val_mae: 1337583.6250 - lr: 0.0010\n",
      "Epoch 84/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1269650.2500 - mae: 1269650.2500 - val_loss: 1335216.0000 - val_mae: 1335216.0000 - lr: 0.0010\n",
      "Epoch 85/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1269451.1250 - mae: 1269451.1250 - val_loss: 1332812.7500 - val_mae: 1332812.7500 - lr: 0.0010\n",
      "Epoch 86/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1265833.1250 - mae: 1265833.1250 - val_loss: 1330306.1250 - val_mae: 1330306.1250 - lr: 0.0010\n",
      "Epoch 87/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1269214.2500 - mae: 1269214.2500 - val_loss: 1327819.0000 - val_mae: 1327819.0000 - lr: 0.0010\n",
      "Epoch 88/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1262241.7500 - mae: 1262241.7500 - val_loss: 1325156.0000 - val_mae: 1325156.0000 - lr: 0.0010\n",
      "Epoch 89/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1250227.1250 - mae: 1250227.1250 - val_loss: 1322343.6250 - val_mae: 1322343.6250 - lr: 0.0010\n",
      "Epoch 90/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1257253.5000 - mae: 1257253.5000 - val_loss: 1319576.6250 - val_mae: 1319576.6250 - lr: 0.0010\n",
      "Epoch 91/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1255411.5000 - mae: 1255411.5000 - val_loss: 1316971.5000 - val_mae: 1316971.5000 - lr: 0.0010\n",
      "Epoch 92/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1255498.2500 - mae: 1255498.2500 - val_loss: 1314302.0000 - val_mae: 1314302.0000 - lr: 0.0010\n",
      "Epoch 93/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1241753.7500 - mae: 1241753.7500 - val_loss: 1311243.1250 - val_mae: 1311243.1250 - lr: 0.0010\n",
      "Epoch 94/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1247595.0000 - mae: 1247595.0000 - val_loss: 1308319.5000 - val_mae: 1308319.5000 - lr: 0.0010\n",
      "Epoch 95/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1242672.0000 - mae: 1242672.0000 - val_loss: 1305279.7500 - val_mae: 1305279.7500 - lr: 0.0010\n",
      "Epoch 96/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1238126.0000 - mae: 1238126.0000 - val_loss: 1302186.8750 - val_mae: 1302186.8750 - lr: 0.0010\n",
      "Epoch 97/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 10ms/step - loss: 1236945.6250 - mae: 1236945.6250 - val_loss: 1299210.8750 - val_mae: 1299210.8750 - lr: 0.0010\n",
      "Epoch 98/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1231494.1250 - mae: 1231494.1250 - val_loss: 1296429.5000 - val_mae: 1296429.6250 - lr: 0.0010\n",
      "Epoch 99/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1224184.0000 - mae: 1224184.0000 - val_loss: 1293324.0000 - val_mae: 1293323.8750 - lr: 0.0010\n",
      "Epoch 100/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1225289.5000 - mae: 1225289.5000 - val_loss: 1290579.2500 - val_mae: 1290579.2500 - lr: 0.0010\n",
      "Epoch 101/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1230786.5000 - mae: 1230786.5000 - val_loss: 1287728.8750 - val_mae: 1287728.8750 - lr: 0.0010\n",
      "Epoch 102/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1228247.6250 - mae: 1228247.6250 - val_loss: 1284861.2500 - val_mae: 1284861.2500 - lr: 0.0010\n",
      "Epoch 103/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1224480.5000 - mae: 1224480.5000 - val_loss: 1282121.7500 - val_mae: 1282121.7500 - lr: 0.0010\n",
      "Epoch 104/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1212198.6250 - mae: 1212198.6250 - val_loss: 1279310.7500 - val_mae: 1279310.7500 - lr: 0.0010\n",
      "Epoch 105/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1226158.6250 - mae: 1226158.6250 - val_loss: 1276567.6250 - val_mae: 1276567.6250 - lr: 0.0010\n",
      "Epoch 106/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1213690.2500 - mae: 1213690.2500 - val_loss: 1274028.1250 - val_mae: 1274028.1250 - lr: 0.0010\n",
      "Epoch 107/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1211491.2500 - mae: 1211491.2500 - val_loss: 1271232.3750 - val_mae: 1271232.3750 - lr: 0.0010\n",
      "Epoch 108/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1216769.1250 - mae: 1216769.1250 - val_loss: 1268777.7500 - val_mae: 1268777.6250 - lr: 0.0010\n",
      "Epoch 109/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1208516.3750 - mae: 1208516.3750 - val_loss: 1266727.0000 - val_mae: 1266727.0000 - lr: 0.0010\n",
      "Epoch 110/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1196924.6250 - mae: 1196924.6250 - val_loss: 1264842.0000 - val_mae: 1264842.0000 - lr: 0.0010\n",
      "Epoch 111/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1205435.0000 - mae: 1205435.0000 - val_loss: 1262923.8750 - val_mae: 1262923.8750 - lr: 0.0010\n",
      "Epoch 112/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1199720.1250 - mae: 1199720.1250 - val_loss: 1260811.0000 - val_mae: 1260810.8750 - lr: 0.0010\n",
      "Epoch 113/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1192105.3750 - mae: 1192105.3750 - val_loss: 1258664.8750 - val_mae: 1258664.8750 - lr: 0.0010\n",
      "Epoch 114/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1213600.0000 - mae: 1213600.1250 - val_loss: 1256613.8750 - val_mae: 1256613.8750 - lr: 0.0010\n",
      "Epoch 115/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1196666.8750 - mae: 1196666.8750 - val_loss: 1254370.7500 - val_mae: 1254370.7500 - lr: 0.0010\n",
      "Epoch 116/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1178547.6250 - mae: 1178547.6250 - val_loss: 1251988.6250 - val_mae: 1251988.6250 - lr: 0.0010\n",
      "Epoch 117/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1174420.1250 - mae: 1174420.1250 - val_loss: 1249366.5000 - val_mae: 1249366.5000 - lr: 0.0010\n",
      "Epoch 118/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1182662.1250 - mae: 1182662.1250 - val_loss: 1246923.1250 - val_mae: 1246923.1250 - lr: 0.0010\n",
      "Epoch 119/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1183612.3750 - mae: 1183612.3750 - val_loss: 1244596.0000 - val_mae: 1244596.0000 - lr: 0.0010\n",
      "Epoch 120/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1183457.8750 - mae: 1183457.8750 - val_loss: 1242412.3750 - val_mae: 1242412.3750 - lr: 0.0010\n",
      "Epoch 121/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1175527.2500 - mae: 1175527.2500 - val_loss: 1240340.1250 - val_mae: 1240340.1250 - lr: 0.0010\n",
      "Epoch 122/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1173758.2500 - mae: 1173758.2500 - val_loss: 1238631.2500 - val_mae: 1238631.2500 - lr: 0.0010\n",
      "Epoch 123/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1167030.0000 - mae: 1167030.0000 - val_loss: 1236233.3750 - val_mae: 1236233.3750 - lr: 0.0010\n",
      "Epoch 124/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1167471.2500 - mae: 1167471.2500 - val_loss: 1233830.3750 - val_mae: 1233830.5000 - lr: 0.0010\n",
      "Epoch 125/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1179896.2500 - mae: 1179896.2500 - val_loss: 1231361.5000 - val_mae: 1231361.3750 - lr: 0.0010\n",
      "Epoch 126/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1163810.7500 - mae: 1163810.7500 - val_loss: 1229014.0000 - val_mae: 1229014.0000 - lr: 0.0010\n",
      "Epoch 127/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1176556.0000 - mae: 1176556.0000 - val_loss: 1226919.1250 - val_mae: 1226919.2500 - lr: 0.0010\n",
      "Epoch 128/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1164743.8750 - mae: 1164743.8750 - val_loss: 1224821.3750 - val_mae: 1224821.3750 - lr: 0.0010\n",
      "Epoch 129/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1165289.1250 - mae: 1165289.1250 - val_loss: 1222958.0000 - val_mae: 1222958.0000 - lr: 0.0010\n",
      "Epoch 130/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1153712.0000 - mae: 1153712.0000 - val_loss: 1220850.3750 - val_mae: 1220850.3750 - lr: 0.0010\n",
      "Epoch 131/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1162537.0000 - mae: 1162537.0000 - val_loss: 1218977.8750 - val_mae: 1218977.8750 - lr: 0.0010\n",
      "Epoch 132/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1163798.7500 - mae: 1163798.7500 - val_loss: 1216993.0000 - val_mae: 1216993.0000 - lr: 0.0010\n",
      "Epoch 133/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1149363.8750 - mae: 1149363.8750 - val_loss: 1214922.3750 - val_mae: 1214922.3750 - lr: 0.0010\n",
      "Epoch 134/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1148596.3750 - mae: 1148596.3750 - val_loss: 1212852.2500 - val_mae: 1212852.2500 - lr: 0.0010\n",
      "Epoch 135/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1139473.0000 - mae: 1139473.0000 - val_loss: 1211860.2500 - val_mae: 1211860.2500 - lr: 0.0010\n",
      "Epoch 136/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1149406.5000 - mae: 1149406.5000 - val_loss: 1211279.1250 - val_mae: 1211279.1250 - lr: 0.0010\n",
      "Epoch 137/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1164964.8750 - mae: 1164964.8750 - val_loss: 1210793.0000 - val_mae: 1210793.0000 - lr: 0.0010\n",
      "Epoch 138/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1142364.2500 - mae: 1142364.2500 - val_loss: 1210500.3750 - val_mae: 1210500.3750 - lr: 0.0010\n",
      "Epoch 139/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1149284.1250 - mae: 1149284.1250 - val_loss: 1210182.2500 - val_mae: 1210182.2500 - lr: 0.0010\n",
      "Epoch 140/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1126448.2500 - mae: 1126448.2500 - val_loss: 1209860.6250 - val_mae: 1209860.6250 - lr: 0.0010\n",
      "Epoch 141/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1134769.7500 - mae: 1134769.7500 - val_loss: 1209576.2500 - val_mae: 1209576.2500 - lr: 0.0010\n",
      "Epoch 142/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1147831.7500 - mae: 1147831.7500 - val_loss: 1209289.7500 - val_mae: 1209289.7500 - lr: 0.0010\n",
      "Epoch 143/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1162692.1250 - mae: 1162692.1250 - val_loss: 1208880.5000 - val_mae: 1208880.5000 - lr: 0.0010\n",
      "Epoch 144/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1130164.1250 - mae: 1130164.1250 - val_loss: 1208639.3750 - val_mae: 1208639.3750 - lr: 0.0010\n",
      "Epoch 145/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 11ms/step - loss: 1138499.7500 - mae: 1138499.7500 - val_loss: 1208586.6250 - val_mae: 1208586.7500 - lr: 0.0010\n",
      "Epoch 146/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1138143.7500 - mae: 1138143.7500 - val_loss: 1208552.5000 - val_mae: 1208552.5000 - lr: 0.0010\n",
      "Epoch 147/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1137338.3750 - mae: 1137338.3750 - val_loss: 1208460.1250 - val_mae: 1208460.1250 - lr: 0.0010\n",
      "Epoch 148/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1139728.0000 - mae: 1139728.0000 - val_loss: 1208442.5000 - val_mae: 1208442.5000 - lr: 0.0010\n",
      "Epoch 149/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1117362.0000 - mae: 1117362.0000 - val_loss: 1208417.6250 - val_mae: 1208417.5000 - lr: 0.0010\n",
      "Epoch 150/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1143260.0000 - mae: 1143260.0000 - val_loss: 1208337.3750 - val_mae: 1208337.2500 - lr: 0.0010\n",
      "Epoch 151/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1141439.5000 - mae: 1141439.5000 - val_loss: 1208339.6250 - val_mae: 1208339.6250 - lr: 0.0010\n",
      "Epoch 152/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1120097.5000 - mae: 1120097.6250 - val_loss: 1208371.7500 - val_mae: 1208371.6250 - lr: 0.0010\n",
      "Epoch 153/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1116717.8750 - mae: 1116717.8750 - val_loss: 1208421.3750 - val_mae: 1208421.3750 - lr: 0.0010\n",
      "Epoch 154/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1129940.3750 - mae: 1129940.3750 - val_loss: 1208420.2500 - val_mae: 1208420.2500 - lr: 0.0010\n",
      "Epoch 155/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1117468.7500 - mae: 1117468.7500 - val_loss: 1208538.7500 - val_mae: 1208538.7500 - lr: 0.0010\n",
      "Epoch 156/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1120164.5000 - mae: 1120164.5000 - val_loss: 1208805.8750 - val_mae: 1208805.8750 - lr: 0.0010\n",
      "Epoch 157/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1130002.5000 - mae: 1130002.5000 - val_loss: 1209054.6250 - val_mae: 1209054.7500 - lr: 0.0010\n",
      "Epoch 158/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1122027.3750 - mae: 1122027.3750 - val_loss: 1209320.2500 - val_mae: 1209320.2500 - lr: 0.0010\n",
      "Epoch 159/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1112820.2500 - mae: 1112820.2500 - val_loss: 1209782.5000 - val_mae: 1209782.5000 - lr: 0.0010\n",
      "Epoch 160/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1099648.2500 - mae: 1099648.2500 - val_loss: 1210242.1250 - val_mae: 1210242.1250 - lr: 0.0010\n",
      "Epoch 161/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1117640.1250 - mae: 1117640.1250 - val_loss: 1210594.8750 - val_mae: 1210594.8750 - lr: 0.0010\n",
      "Epoch 162/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1128486.3750 - mae: 1128486.3750 - val_loss: 1210967.8750 - val_mae: 1210967.8750 - lr: 0.0010\n",
      "Epoch 163/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1102647.2500 - mae: 1102647.2500 - val_loss: 1211526.3750 - val_mae: 1211526.3750 - lr: 0.0010\n",
      "Epoch 164/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1090124.0000 - mae: 1090124.0000 - val_loss: 1212337.2500 - val_mae: 1212337.2500 - lr: 0.0010\n",
      "Epoch 165/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1112848.0000 - mae: 1112848.0000 - val_loss: 1213845.3750 - val_mae: 1213845.5000 - lr: 0.0010\n",
      "Epoch 166/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1118248.1250 - mae: 1118248.1250 - val_loss: 1214652.3750 - val_mae: 1214652.2500 - lr: 0.0010\n",
      "Epoch 167/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1113929.3750 - mae: 1113929.3750 - val_loss: 1215612.8750 - val_mae: 1215612.8750 - lr: 0.0010\n",
      "Epoch 168/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1101773.8750 - mae: 1101773.8750 - val_loss: 1216967.6250 - val_mae: 1216967.6250 - lr: 0.0010\n",
      "Epoch 169/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1104373.3750 - mae: 1104373.3750 - val_loss: 1218170.6250 - val_mae: 1218170.6250 - lr: 0.0010\n",
      "Epoch 170/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1086459.2500 - mae: 1086459.2500 - val_loss: 1219474.2500 - val_mae: 1219474.2500 - lr: 0.0010\n",
      "Epoch 171/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1108058.3750 - mae: 1108058.3750 - val_loss: 1219583.7500 - val_mae: 1219583.7500 - lr: 2.0000e-04\n",
      "Epoch 172/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1110240.2500 - mae: 1110240.2500 - val_loss: 1219763.8750 - val_mae: 1219763.8750 - lr: 2.0000e-04\n",
      "Epoch 173/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1107275.2500 - mae: 1107275.2500 - val_loss: 1220018.0000 - val_mae: 1220017.8750 - lr: 2.0000e-04\n",
      "Epoch 174/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1092610.3750 - mae: 1092610.3750 - val_loss: 1220276.5000 - val_mae: 1220276.5000 - lr: 2.0000e-04\n",
      "Epoch 175/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1097795.2500 - mae: 1097795.2500 - val_loss: 1220474.1250 - val_mae: 1220474.1250 - lr: 2.0000e-04\n",
      "Epoch 176/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1119948.0000 - mae: 1119948.0000 - val_loss: 1220625.2500 - val_mae: 1220625.2500 - lr: 2.0000e-04\n",
      "Epoch 177/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1101898.7500 - mae: 1101898.7500 - val_loss: 1220873.3750 - val_mae: 1220873.3750 - lr: 2.0000e-04\n",
      "Epoch 178/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1104890.7500 - mae: 1104890.7500 - val_loss: 1220995.5000 - val_mae: 1220995.5000 - lr: 2.0000e-04\n",
      "Epoch 179/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1089811.2500 - mae: 1089811.2500 - val_loss: 1221130.5000 - val_mae: 1221130.5000 - lr: 2.0000e-04\n",
      "Epoch 180/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1105863.0000 - mae: 1105863.0000 - val_loss: 1221275.3750 - val_mae: 1221275.3750 - lr: 2.0000e-04\n",
      "Epoch 181/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1120226.5000 - mae: 1120226.5000 - val_loss: 1221406.5000 - val_mae: 1221406.5000 - lr: 2.0000e-04\n",
      "Epoch 182/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1114644.2500 - mae: 1114644.2500 - val_loss: 1221516.0000 - val_mae: 1221516.0000 - lr: 2.0000e-04\n",
      "Epoch 183/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1093450.7500 - mae: 1093450.7500 - val_loss: 1221623.1250 - val_mae: 1221623.1250 - lr: 2.0000e-04\n",
      "Epoch 184/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1113819.3750 - mae: 1113819.3750 - val_loss: 1221705.7500 - val_mae: 1221705.7500 - lr: 2.0000e-04\n",
      "Epoch 185/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1082166.2500 - mae: 1082166.2500 - val_loss: 1221886.3750 - val_mae: 1221886.3750 - lr: 2.0000e-04\n",
      "Epoch 186/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1095568.6250 - mae: 1095568.6250 - val_loss: 1222031.1250 - val_mae: 1222031.1250 - lr: 2.0000e-04\n",
      "Epoch 187/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1103925.8750 - mae: 1103925.8750 - val_loss: 1222179.7500 - val_mae: 1222179.7500 - lr: 2.0000e-04\n",
      "Epoch 188/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1118611.3750 - mae: 1118611.3750 - val_loss: 1222184.7500 - val_mae: 1222184.7500 - lr: 2.0000e-04\n",
      "Epoch 189/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1092050.0000 - mae: 1092050.0000 - val_loss: 1222260.3750 - val_mae: 1222260.3750 - lr: 2.0000e-04\n",
      "Epoch 190/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1104623.3750 - mae: 1104623.3750 - val_loss: 1222362.1250 - val_mae: 1222362.1250 - lr: 2.0000e-04\n",
      "6/6 [==============================] - 0s 998us/step - loss: 1316436.5000 - mae: 1316436.5000\n",
      "\n",
      "model acc: 1316436.5000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, validation_split=0.3, epochs=1000, batch_size=64, verbose=1, callbacks=[early_stopping_callback,checkpointer,reduce_lr])\n",
    "print(\"\\nmodel acc: %.4f\" % (model.evaluate(X_test, y_test)[1]))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1341555 16,rmsprop 0.2 20 40 1000 64\n",
    "1339283 16,Nadam 0.2 20 40 1000 64\n",
    "1316436 16,Nadam 0.2 20 40 1000 64\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정규화 안하는게 더 좋은 결과를 낳음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 보팅(pycaret, logistic regression, linear discriminant, ridge classifier)\n",
    "accuracy - 정확도,\n",
    "f1 score - 모델 성능, 얼마나 잘 맞추는가\n",
    "이 모델들 외에도, knn, xgboost, ada boost,cat boost, random forest 등 많이 해봤지만 다 정확도와 f1 score가 낮게 나와서 뺌"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4635316.629931727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Seo\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(penalty = 'l2', random_state=100)\n",
    "lr.fit(X_train, y_train)\n",
    "lr_pred1 = lr.predict(X_test)\n",
    "test_RMSE = np.sqrt(mean_squared_error(lr_pred1, y_test))\n",
    "print(test_RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### linear discriminant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2225306.924692389\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "cat = CatBoostRegressor(random_state = 42, silent = True) # CatBoostRegressor\n",
    "\n",
    "cat.fit(X_train, y_train)\n",
    "\n",
    "cat_predict = cat.predict(X_test)\n",
    "test_RMSE = np.sqrt(mean_squared_error(cat_predict, y_test))\n",
    "print(test_RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rigde classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.791907514450867\n",
      "F1 score: 0.4375\n"
     ]
    }
   ],
   "source": [
    "rc = RidgeClassifier(random_state = 100)\n",
    "rc.fit(X_train, y_train)\n",
    "rc_pred1 = rc.predict(X_test)\n",
    "print(\"Accuracy:\",accuracy_score(y_test, rc_pred1))\n",
    "print(\"F1 score:\",f1_score(rc_pred1, y_test))\n",
    "# 좋은 결과가 나오지만 보팅에 넣을 수가 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pycaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.regression import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(df_fin, test_size=0.3, random_state=100)\n",
    "cat_features = ['genre_rank', 'direct_rank','dist_rank']  # 범주 변수들 설정해줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_b9c487ba_d280_11ec_86cc_7085c2294e08row42_col1{\n",
       "            background-color:  lightgreen;\n",
       "        }</style><table id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Description</th>        <th class=\"col_heading level0 col1\" >Value</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row0_col0\" class=\"data row0 col0\" >session_id</td>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row0_col1\" class=\"data row0 col1\" >8062</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row1_col1\" class=\"data row1 col1\" >Target</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row2_col0\" class=\"data row2 col0\" >Original Data</td>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row2_col1\" class=\"data row2 col1\" >(402, 8)</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row3_col0\" class=\"data row3 col0\" >Missing Values</td>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row3_col1\" class=\"data row3 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row4_col0\" class=\"data row4 col0\" >Numeric Features</td>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row4_col1\" class=\"data row4 col1\" >4</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row5_col0\" class=\"data row5 col0\" >Categorical Features</td>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row5_col1\" class=\"data row5 col1\" >3</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row6_col0\" class=\"data row6 col0\" >Ordinal Features</td>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row6_col1\" class=\"data row6 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row7_col0\" class=\"data row7 col0\" >High Cardinality Features</td>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row7_col1\" class=\"data row7 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row8_col0\" class=\"data row8 col0\" >High Cardinality Method</td>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row8_col1\" class=\"data row8 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row9_col0\" class=\"data row9 col0\" >Transformed Train Set</td>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row9_col1\" class=\"data row9 col1\" >(281, 114)</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row10_col0\" class=\"data row10 col0\" >Transformed Test Set</td>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row10_col1\" class=\"data row10 col1\" >(121, 114)</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row11_col0\" class=\"data row11 col0\" >Shuffle Train-Test</td>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row11_col1\" class=\"data row11 col1\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row12_col0\" class=\"data row12 col0\" >Stratify Train-Test</td>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row12_col1\" class=\"data row12 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row13_col0\" class=\"data row13 col0\" >Fold Generator</td>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row13_col1\" class=\"data row13 col1\" >KFold</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row14_col0\" class=\"data row14 col0\" >Fold Number</td>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row14_col1\" class=\"data row14 col1\" >10</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row15_col0\" class=\"data row15 col0\" >CPU Jobs</td>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row15_col1\" class=\"data row15 col1\" >-1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row16_col0\" class=\"data row16 col0\" >Use GPU</td>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row16_col1\" class=\"data row16 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row17_col0\" class=\"data row17 col0\" >Log Experiment</td>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row17_col1\" class=\"data row17 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row18_col0\" class=\"data row18 col0\" >Experiment Name</td>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row18_col1\" class=\"data row18 col1\" >reg-default-name</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row19_col0\" class=\"data row19 col0\" >USI</td>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row19_col1\" class=\"data row19 col1\" >64e1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row20_col0\" class=\"data row20 col0\" >Imputation Type</td>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row20_col1\" class=\"data row20 col1\" >simple</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row21_col0\" class=\"data row21 col0\" >Iterative Imputation Iteration</td>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row21_col1\" class=\"data row21 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row22_col0\" class=\"data row22 col0\" >Numeric Imputer</td>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row22_col1\" class=\"data row22 col1\" >mean</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row23_col0\" class=\"data row23 col0\" >Iterative Imputation Numeric Model</td>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row23_col1\" class=\"data row23 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08level0_row24\" class=\"row_heading level0 row24\" >24</th>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row24_col0\" class=\"data row24 col0\" >Categorical Imputer</td>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row24_col1\" class=\"data row24 col1\" >constant</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08level0_row25\" class=\"row_heading level0 row25\" >25</th>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row25_col0\" class=\"data row25 col0\" >Iterative Imputation Categorical Model</td>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row25_col1\" class=\"data row25 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08level0_row26\" class=\"row_heading level0 row26\" >26</th>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row26_col0\" class=\"data row26 col0\" >Unknown Categoricals Handling</td>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row26_col1\" class=\"data row26 col1\" >least_frequent</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08level0_row27\" class=\"row_heading level0 row27\" >27</th>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row27_col0\" class=\"data row27 col0\" >Normalize</td>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row27_col1\" class=\"data row27 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08level0_row28\" class=\"row_heading level0 row28\" >28</th>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row28_col0\" class=\"data row28 col0\" >Normalize Method</td>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row28_col1\" class=\"data row28 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08level0_row29\" class=\"row_heading level0 row29\" >29</th>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row29_col0\" class=\"data row29 col0\" >Transformation</td>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row29_col1\" class=\"data row29 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08level0_row30\" class=\"row_heading level0 row30\" >30</th>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row30_col0\" class=\"data row30 col0\" >Transformation Method</td>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row30_col1\" class=\"data row30 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08level0_row31\" class=\"row_heading level0 row31\" >31</th>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row31_col0\" class=\"data row31 col0\" >PCA</td>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row31_col1\" class=\"data row31 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08level0_row32\" class=\"row_heading level0 row32\" >32</th>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row32_col0\" class=\"data row32 col0\" >PCA Method</td>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row32_col1\" class=\"data row32 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08level0_row33\" class=\"row_heading level0 row33\" >33</th>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row33_col0\" class=\"data row33 col0\" >PCA Components</td>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row33_col1\" class=\"data row33 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08level0_row34\" class=\"row_heading level0 row34\" >34</th>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row34_col0\" class=\"data row34 col0\" >Ignore Low Variance</td>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row34_col1\" class=\"data row34 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08level0_row35\" class=\"row_heading level0 row35\" >35</th>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row35_col0\" class=\"data row35 col0\" >Combine Rare Levels</td>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row35_col1\" class=\"data row35 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08level0_row36\" class=\"row_heading level0 row36\" >36</th>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row36_col0\" class=\"data row36 col0\" >Rare Level Threshold</td>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row36_col1\" class=\"data row36 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08level0_row37\" class=\"row_heading level0 row37\" >37</th>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row37_col0\" class=\"data row37 col0\" >Numeric Binning</td>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row37_col1\" class=\"data row37 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08level0_row38\" class=\"row_heading level0 row38\" >38</th>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row38_col0\" class=\"data row38 col0\" >Remove Outliers</td>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row38_col1\" class=\"data row38 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08level0_row39\" class=\"row_heading level0 row39\" >39</th>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row39_col0\" class=\"data row39 col0\" >Outliers Threshold</td>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row39_col1\" class=\"data row39 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08level0_row40\" class=\"row_heading level0 row40\" >40</th>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row40_col0\" class=\"data row40 col0\" >Remove Multicollinearity</td>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row40_col1\" class=\"data row40 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08level0_row41\" class=\"row_heading level0 row41\" >41</th>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row41_col0\" class=\"data row41 col0\" >Multicollinearity Threshold</td>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row41_col1\" class=\"data row41 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08level0_row42\" class=\"row_heading level0 row42\" >42</th>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row42_col0\" class=\"data row42 col0\" >Remove Perfect Collinearity</td>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row42_col1\" class=\"data row42 col1\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08level0_row43\" class=\"row_heading level0 row43\" >43</th>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row43_col0\" class=\"data row43 col0\" >Clustering</td>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row43_col1\" class=\"data row43 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08level0_row44\" class=\"row_heading level0 row44\" >44</th>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row44_col0\" class=\"data row44 col0\" >Clustering Iteration</td>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row44_col1\" class=\"data row44 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08level0_row45\" class=\"row_heading level0 row45\" >45</th>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row45_col0\" class=\"data row45 col0\" >Polynomial Features</td>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row45_col1\" class=\"data row45 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08level0_row46\" class=\"row_heading level0 row46\" >46</th>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row46_col0\" class=\"data row46 col0\" >Polynomial Degree</td>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row46_col1\" class=\"data row46 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08level0_row47\" class=\"row_heading level0 row47\" >47</th>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row47_col0\" class=\"data row47 col0\" >Trignometry Features</td>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row47_col1\" class=\"data row47 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08level0_row48\" class=\"row_heading level0 row48\" >48</th>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row48_col0\" class=\"data row48 col0\" >Polynomial Threshold</td>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row48_col1\" class=\"data row48 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08level0_row49\" class=\"row_heading level0 row49\" >49</th>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row49_col0\" class=\"data row49 col0\" >Group Features</td>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row49_col1\" class=\"data row49 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08level0_row50\" class=\"row_heading level0 row50\" >50</th>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row50_col0\" class=\"data row50 col0\" >Feature Selection</td>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row50_col1\" class=\"data row50 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08level0_row51\" class=\"row_heading level0 row51\" >51</th>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row51_col0\" class=\"data row51 col0\" >Feature Selection Method</td>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row51_col1\" class=\"data row51 col1\" >classic</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08level0_row52\" class=\"row_heading level0 row52\" >52</th>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row52_col0\" class=\"data row52 col0\" >Features Selection Threshold</td>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row52_col1\" class=\"data row52 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08level0_row53\" class=\"row_heading level0 row53\" >53</th>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row53_col0\" class=\"data row53 col0\" >Feature Interaction</td>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row53_col1\" class=\"data row53 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08level0_row54\" class=\"row_heading level0 row54\" >54</th>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row54_col0\" class=\"data row54 col0\" >Feature Ratio</td>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row54_col1\" class=\"data row54 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08level0_row55\" class=\"row_heading level0 row55\" >55</th>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row55_col0\" class=\"data row55 col0\" >Interaction Threshold</td>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row55_col1\" class=\"data row55 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08level0_row56\" class=\"row_heading level0 row56\" >56</th>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row56_col0\" class=\"data row56 col0\" >Transform Target</td>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row56_col1\" class=\"data row56 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08level0_row57\" class=\"row_heading level0 row57\" >57</th>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row57_col0\" class=\"data row57 col0\" >Transform Target Method</td>\n",
       "                        <td id=\"T_b9c487ba_d280_11ec_86cc_7085c2294e08row57_col1\" class=\"data row57 col1\" >box-cox</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x15a7cf58310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "setup_clf = setup(data = train, target= 'Target', fold_shuffle=True, categorical_features=cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_cd02590d_d280_11ec_967d_7085c2294e08 th {\n",
       "          text-align: left;\n",
       "    }#T_cd02590d_d280_11ec_967d_7085c2294e08row0_col0,#T_cd02590d_d280_11ec_967d_7085c2294e08row0_col1,#T_cd02590d_d280_11ec_967d_7085c2294e08row0_col5,#T_cd02590d_d280_11ec_967d_7085c2294e08row0_col6,#T_cd02590d_d280_11ec_967d_7085c2294e08row1_col0,#T_cd02590d_d280_11ec_967d_7085c2294e08row1_col1,#T_cd02590d_d280_11ec_967d_7085c2294e08row1_col2,#T_cd02590d_d280_11ec_967d_7085c2294e08row1_col3,#T_cd02590d_d280_11ec_967d_7085c2294e08row1_col4,#T_cd02590d_d280_11ec_967d_7085c2294e08row1_col5,#T_cd02590d_d280_11ec_967d_7085c2294e08row1_col6,#T_cd02590d_d280_11ec_967d_7085c2294e08row2_col0,#T_cd02590d_d280_11ec_967d_7085c2294e08row2_col1,#T_cd02590d_d280_11ec_967d_7085c2294e08row2_col2,#T_cd02590d_d280_11ec_967d_7085c2294e08row2_col3,#T_cd02590d_d280_11ec_967d_7085c2294e08row2_col4,#T_cd02590d_d280_11ec_967d_7085c2294e08row2_col5,#T_cd02590d_d280_11ec_967d_7085c2294e08row2_col6,#T_cd02590d_d280_11ec_967d_7085c2294e08row3_col0,#T_cd02590d_d280_11ec_967d_7085c2294e08row3_col1,#T_cd02590d_d280_11ec_967d_7085c2294e08row3_col2,#T_cd02590d_d280_11ec_967d_7085c2294e08row3_col3,#T_cd02590d_d280_11ec_967d_7085c2294e08row3_col4,#T_cd02590d_d280_11ec_967d_7085c2294e08row3_col5,#T_cd02590d_d280_11ec_967d_7085c2294e08row3_col6,#T_cd02590d_d280_11ec_967d_7085c2294e08row4_col0,#T_cd02590d_d280_11ec_967d_7085c2294e08row4_col1,#T_cd02590d_d280_11ec_967d_7085c2294e08row4_col2,#T_cd02590d_d280_11ec_967d_7085c2294e08row4_col3,#T_cd02590d_d280_11ec_967d_7085c2294e08row4_col4,#T_cd02590d_d280_11ec_967d_7085c2294e08row4_col5,#T_cd02590d_d280_11ec_967d_7085c2294e08row4_col6,#T_cd02590d_d280_11ec_967d_7085c2294e08row5_col0,#T_cd02590d_d280_11ec_967d_7085c2294e08row5_col2,#T_cd02590d_d280_11ec_967d_7085c2294e08row5_col3,#T_cd02590d_d280_11ec_967d_7085c2294e08row5_col4,#T_cd02590d_d280_11ec_967d_7085c2294e08row5_col6,#T_cd02590d_d280_11ec_967d_7085c2294e08row6_col0,#T_cd02590d_d280_11ec_967d_7085c2294e08row6_col1,#T_cd02590d_d280_11ec_967d_7085c2294e08row6_col2,#T_cd02590d_d280_11ec_967d_7085c2294e08row6_col3,#T_cd02590d_d280_11ec_967d_7085c2294e08row6_col4,#T_cd02590d_d280_11ec_967d_7085c2294e08row6_col5,#T_cd02590d_d280_11ec_967d_7085c2294e08row6_col6,#T_cd02590d_d280_11ec_967d_7085c2294e08row7_col0,#T_cd02590d_d280_11ec_967d_7085c2294e08row7_col1,#T_cd02590d_d280_11ec_967d_7085c2294e08row7_col2,#T_cd02590d_d280_11ec_967d_7085c2294e08row7_col3,#T_cd02590d_d280_11ec_967d_7085c2294e08row7_col4,#T_cd02590d_d280_11ec_967d_7085c2294e08row7_col5,#T_cd02590d_d280_11ec_967d_7085c2294e08row7_col6,#T_cd02590d_d280_11ec_967d_7085c2294e08row8_col0,#T_cd02590d_d280_11ec_967d_7085c2294e08row8_col1,#T_cd02590d_d280_11ec_967d_7085c2294e08row8_col2,#T_cd02590d_d280_11ec_967d_7085c2294e08row8_col3,#T_cd02590d_d280_11ec_967d_7085c2294e08row8_col4,#T_cd02590d_d280_11ec_967d_7085c2294e08row8_col5,#T_cd02590d_d280_11ec_967d_7085c2294e08row8_col6,#T_cd02590d_d280_11ec_967d_7085c2294e08row9_col0,#T_cd02590d_d280_11ec_967d_7085c2294e08row9_col1,#T_cd02590d_d280_11ec_967d_7085c2294e08row9_col2,#T_cd02590d_d280_11ec_967d_7085c2294e08row9_col3,#T_cd02590d_d280_11ec_967d_7085c2294e08row9_col4,#T_cd02590d_d280_11ec_967d_7085c2294e08row9_col5,#T_cd02590d_d280_11ec_967d_7085c2294e08row9_col6,#T_cd02590d_d280_11ec_967d_7085c2294e08row10_col0,#T_cd02590d_d280_11ec_967d_7085c2294e08row10_col1,#T_cd02590d_d280_11ec_967d_7085c2294e08row10_col2,#T_cd02590d_d280_11ec_967d_7085c2294e08row10_col3,#T_cd02590d_d280_11ec_967d_7085c2294e08row10_col4,#T_cd02590d_d280_11ec_967d_7085c2294e08row10_col5,#T_cd02590d_d280_11ec_967d_7085c2294e08row10_col6,#T_cd02590d_d280_11ec_967d_7085c2294e08row11_col0,#T_cd02590d_d280_11ec_967d_7085c2294e08row11_col1,#T_cd02590d_d280_11ec_967d_7085c2294e08row11_col2,#T_cd02590d_d280_11ec_967d_7085c2294e08row11_col3,#T_cd02590d_d280_11ec_967d_7085c2294e08row11_col4,#T_cd02590d_d280_11ec_967d_7085c2294e08row11_col5,#T_cd02590d_d280_11ec_967d_7085c2294e08row11_col6,#T_cd02590d_d280_11ec_967d_7085c2294e08row12_col0,#T_cd02590d_d280_11ec_967d_7085c2294e08row12_col1,#T_cd02590d_d280_11ec_967d_7085c2294e08row12_col2,#T_cd02590d_d280_11ec_967d_7085c2294e08row12_col3,#T_cd02590d_d280_11ec_967d_7085c2294e08row12_col4,#T_cd02590d_d280_11ec_967d_7085c2294e08row12_col5,#T_cd02590d_d280_11ec_967d_7085c2294e08row12_col6,#T_cd02590d_d280_11ec_967d_7085c2294e08row13_col0,#T_cd02590d_d280_11ec_967d_7085c2294e08row13_col1,#T_cd02590d_d280_11ec_967d_7085c2294e08row13_col2,#T_cd02590d_d280_11ec_967d_7085c2294e08row13_col3,#T_cd02590d_d280_11ec_967d_7085c2294e08row13_col4,#T_cd02590d_d280_11ec_967d_7085c2294e08row13_col5,#T_cd02590d_d280_11ec_967d_7085c2294e08row13_col6,#T_cd02590d_d280_11ec_967d_7085c2294e08row14_col0,#T_cd02590d_d280_11ec_967d_7085c2294e08row14_col1,#T_cd02590d_d280_11ec_967d_7085c2294e08row14_col2,#T_cd02590d_d280_11ec_967d_7085c2294e08row14_col3,#T_cd02590d_d280_11ec_967d_7085c2294e08row14_col4,#T_cd02590d_d280_11ec_967d_7085c2294e08row14_col5,#T_cd02590d_d280_11ec_967d_7085c2294e08row14_col6,#T_cd02590d_d280_11ec_967d_7085c2294e08row15_col0,#T_cd02590d_d280_11ec_967d_7085c2294e08row15_col1,#T_cd02590d_d280_11ec_967d_7085c2294e08row15_col2,#T_cd02590d_d280_11ec_967d_7085c2294e08row15_col3,#T_cd02590d_d280_11ec_967d_7085c2294e08row15_col4,#T_cd02590d_d280_11ec_967d_7085c2294e08row15_col5,#T_cd02590d_d280_11ec_967d_7085c2294e08row15_col6,#T_cd02590d_d280_11ec_967d_7085c2294e08row16_col0,#T_cd02590d_d280_11ec_967d_7085c2294e08row16_col1,#T_cd02590d_d280_11ec_967d_7085c2294e08row16_col2,#T_cd02590d_d280_11ec_967d_7085c2294e08row16_col3,#T_cd02590d_d280_11ec_967d_7085c2294e08row16_col4,#T_cd02590d_d280_11ec_967d_7085c2294e08row16_col5,#T_cd02590d_d280_11ec_967d_7085c2294e08row17_col0,#T_cd02590d_d280_11ec_967d_7085c2294e08row17_col1,#T_cd02590d_d280_11ec_967d_7085c2294e08row17_col2,#T_cd02590d_d280_11ec_967d_7085c2294e08row17_col3,#T_cd02590d_d280_11ec_967d_7085c2294e08row17_col4,#T_cd02590d_d280_11ec_967d_7085c2294e08row17_col5,#T_cd02590d_d280_11ec_967d_7085c2294e08row17_col6,#T_cd02590d_d280_11ec_967d_7085c2294e08row18_col0,#T_cd02590d_d280_11ec_967d_7085c2294e08row18_col1,#T_cd02590d_d280_11ec_967d_7085c2294e08row18_col2,#T_cd02590d_d280_11ec_967d_7085c2294e08row18_col3,#T_cd02590d_d280_11ec_967d_7085c2294e08row18_col4,#T_cd02590d_d280_11ec_967d_7085c2294e08row18_col5,#T_cd02590d_d280_11ec_967d_7085c2294e08row18_col6,#T_cd02590d_d280_11ec_967d_7085c2294e08row19_col0,#T_cd02590d_d280_11ec_967d_7085c2294e08row19_col1,#T_cd02590d_d280_11ec_967d_7085c2294e08row19_col2,#T_cd02590d_d280_11ec_967d_7085c2294e08row19_col3,#T_cd02590d_d280_11ec_967d_7085c2294e08row19_col4,#T_cd02590d_d280_11ec_967d_7085c2294e08row19_col5,#T_cd02590d_d280_11ec_967d_7085c2294e08row19_col6{\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "        }#T_cd02590d_d280_11ec_967d_7085c2294e08row0_col2,#T_cd02590d_d280_11ec_967d_7085c2294e08row0_col3,#T_cd02590d_d280_11ec_967d_7085c2294e08row0_col4,#T_cd02590d_d280_11ec_967d_7085c2294e08row5_col1,#T_cd02590d_d280_11ec_967d_7085c2294e08row5_col5,#T_cd02590d_d280_11ec_967d_7085c2294e08row16_col6{\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            background-color:  yellow;\n",
       "        }#T_cd02590d_d280_11ec_967d_7085c2294e08row0_col7,#T_cd02590d_d280_11ec_967d_7085c2294e08row1_col7,#T_cd02590d_d280_11ec_967d_7085c2294e08row2_col7,#T_cd02590d_d280_11ec_967d_7085c2294e08row3_col7,#T_cd02590d_d280_11ec_967d_7085c2294e08row4_col7,#T_cd02590d_d280_11ec_967d_7085c2294e08row5_col7,#T_cd02590d_d280_11ec_967d_7085c2294e08row6_col7,#T_cd02590d_d280_11ec_967d_7085c2294e08row7_col7,#T_cd02590d_d280_11ec_967d_7085c2294e08row8_col7,#T_cd02590d_d280_11ec_967d_7085c2294e08row9_col7,#T_cd02590d_d280_11ec_967d_7085c2294e08row10_col7,#T_cd02590d_d280_11ec_967d_7085c2294e08row11_col7,#T_cd02590d_d280_11ec_967d_7085c2294e08row12_col7,#T_cd02590d_d280_11ec_967d_7085c2294e08row13_col7,#T_cd02590d_d280_11ec_967d_7085c2294e08row14_col7,#T_cd02590d_d280_11ec_967d_7085c2294e08row15_col7,#T_cd02590d_d280_11ec_967d_7085c2294e08row16_col7,#T_cd02590d_d280_11ec_967d_7085c2294e08row18_col7,#T_cd02590d_d280_11ec_967d_7085c2294e08row19_col7{\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            background-color:  lightgrey;\n",
       "        }#T_cd02590d_d280_11ec_967d_7085c2294e08row17_col7{\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            background-color:  yellow;\n",
       "            background-color:  lightgrey;\n",
       "        }</style><table id=\"T_cd02590d_d280_11ec_967d_7085c2294e08\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Model</th>        <th class=\"col_heading level0 col1\" >MAE</th>        <th class=\"col_heading level0 col2\" >MSE</th>        <th class=\"col_heading level0 col3\" >RMSE</th>        <th class=\"col_heading level0 col4\" >R2</th>        <th class=\"col_heading level0 col5\" >RMSLE</th>        <th class=\"col_heading level0 col6\" >MAPE</th>        <th class=\"col_heading level0 col7\" >TT (Sec)</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_cd02590d_d280_11ec_967d_7085c2294e08level0_row0\" class=\"row_heading level0 row0\" >ridge</th>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row0_col0\" class=\"data row0 col0\" >Ridge Regression</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row0_col1\" class=\"data row0 col1\" >1249348.1500</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row0_col2\" class=\"data row0 col2\" >4031297250918.3999</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row0_col3\" class=\"data row0 col3\" >1986415.6250</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row0_col4\" class=\"data row0 col4\" >0.4619</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row0_col5\" class=\"data row0 col5\" >3.0455</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row0_col6\" class=\"data row0 col6\" >158.7325</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row0_col7\" class=\"data row0 col7\" >0.0120</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cd02590d_d280_11ec_967d_7085c2294e08level0_row1\" class=\"row_heading level0 row1\" >en</th>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row1_col0\" class=\"data row1 col0\" >Elastic Net</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row1_col1\" class=\"data row1 col1\" >1210550.6000</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row1_col2\" class=\"data row1 col2\" >4172685980467.2002</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row1_col3\" class=\"data row1 col3\" >2023363.1750</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row1_col4\" class=\"data row1 col4\" >0.4429</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row1_col5\" class=\"data row1 col5\" >2.8611</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row1_col6\" class=\"data row1 col6\" >118.3336</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row1_col7\" class=\"data row1 col7\" >0.0180</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cd02590d_d280_11ec_967d_7085c2294e08level0_row2\" class=\"row_heading level0 row2\" >rf</th>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row2_col0\" class=\"data row2 col0\" >Random Forest Regressor</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row2_col1\" class=\"data row2 col1\" >1070719.5135</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row2_col2\" class=\"data row2 col2\" >4203318835838.9463</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row2_col3\" class=\"data row2 col3\" >2030313.6860</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row2_col4\" class=\"data row2 col4\" >0.4332</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row2_col5\" class=\"data row2 col5\" >1.5403</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row2_col6\" class=\"data row2 col6\" >11.4691</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row2_col7\" class=\"data row2 col7\" >0.1500</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cd02590d_d280_11ec_967d_7085c2294e08level0_row3\" class=\"row_heading level0 row3\" >gbr</th>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row3_col0\" class=\"data row3 col0\" >Gradient Boosting Regressor</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row3_col1\" class=\"data row3 col1\" >1072954.9604</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row3_col2\" class=\"data row3 col2\" >4306356245402.4897</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row3_col3\" class=\"data row3 col3\" >2060174.7240</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row3_col4\" class=\"data row3 col4\" >0.4157</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row3_col5\" class=\"data row3 col5\" >2.2833</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row3_col6\" class=\"data row3 col6\" >39.6001</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row3_col7\" class=\"data row3 col7\" >0.0420</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cd02590d_d280_11ec_967d_7085c2294e08level0_row4\" class=\"row_heading level0 row4\" >br</th>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row4_col0\" class=\"data row4 col0\" >Bayesian Ridge</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row4_col1\" class=\"data row4 col1\" >1212422.0319</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row4_col2\" class=\"data row4 col2\" >4308619773003.8232</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row4_col3\" class=\"data row4 col3\" >2051784.1355</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row4_col4\" class=\"data row4 col4\" >0.4275</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row4_col5\" class=\"data row4 col5\" >2.7954</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row4_col6\" class=\"data row4 col6\" >94.1566</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row4_col7\" class=\"data row4 col7\" >0.0100</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cd02590d_d280_11ec_967d_7085c2294e08level0_row5\" class=\"row_heading level0 row5\" >et</th>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row5_col0\" class=\"data row5 col0\" >Extra Trees Regressor</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row5_col1\" class=\"data row5 col1\" >1033751.0817</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row5_col2\" class=\"data row5 col2\" >4331332918972.5342</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row5_col3\" class=\"data row5 col3\" >2048068.4764</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row5_col4\" class=\"data row5 col4\" >0.4213</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row5_col5\" class=\"data row5 col5\" >1.5354</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row5_col6\" class=\"data row5 col6\" >10.5809</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row5_col7\" class=\"data row5 col7\" >0.1260</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cd02590d_d280_11ec_967d_7085c2294e08level0_row6\" class=\"row_heading level0 row6\" >catboost</th>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row6_col0\" class=\"data row6 col0\" >CatBoost Regressor</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row6_col1\" class=\"data row6 col1\" >1091839.5605</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row6_col2\" class=\"data row6 col2\" >4388761199683.4858</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row6_col3\" class=\"data row6 col3\" >2077939.4173</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row6_col4\" class=\"data row6 col4\" >0.3959</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row6_col5\" class=\"data row6 col5\" >2.2131</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row6_col6\" class=\"data row6 col6\" >35.4924</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row6_col7\" class=\"data row6 col7\" >1.0180</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cd02590d_d280_11ec_967d_7085c2294e08level0_row7\" class=\"row_heading level0 row7\" >lightgbm</th>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row7_col0\" class=\"data row7 col0\" >Light Gradient Boosting Machine</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row7_col1\" class=\"data row7 col1\" >1224993.8391</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row7_col2\" class=\"data row7 col2\" >4495803681110.3721</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row7_col3\" class=\"data row7 col3\" >2095489.2067</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row7_col4\" class=\"data row7 col4\" >0.3946</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row7_col5\" class=\"data row7 col5\" >2.4879</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row7_col6\" class=\"data row7 col6\" >38.6222</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row7_col7\" class=\"data row7 col7\" >0.2200</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cd02590d_d280_11ec_967d_7085c2294e08level0_row8\" class=\"row_heading level0 row8\" >xgboost</th>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row8_col0\" class=\"data row8 col0\" >Extreme Gradient Boosting</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row8_col1\" class=\"data row8 col1\" >1137766.3625</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row8_col2\" class=\"data row8 col2\" >4736575288115.2002</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row8_col3\" class=\"data row8 col3\" >2167323.5750</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row8_col4\" class=\"data row8 col4\" >0.3413</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row8_col5\" class=\"data row8 col5\" >1.8721</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row8_col6\" class=\"data row8 col6\" >23.3805</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row8_col7\" class=\"data row8 col7\" >0.1040</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cd02590d_d280_11ec_967d_7085c2294e08level0_row9\" class=\"row_heading level0 row9\" >huber</th>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row9_col0\" class=\"data row9 col0\" >Huber Regressor</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row9_col1\" class=\"data row9 col1\" >1070230.7345</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row9_col2\" class=\"data row9 col2\" >4803973691466.9619</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row9_col3\" class=\"data row9 col3\" >2162503.2662</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row9_col4\" class=\"data row9 col4\" >0.3672</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row9_col5\" class=\"data row9 col5\" >2.4120</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row9_col6\" class=\"data row9 col6\" >54.0540</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row9_col7\" class=\"data row9 col7\" >0.0300</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cd02590d_d280_11ec_967d_7085c2294e08level0_row10\" class=\"row_heading level0 row10\" >ada</th>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row10_col0\" class=\"data row10 col0\" >AdaBoost Regressor</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row10_col1\" class=\"data row10 col1\" >1743207.1674</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row10_col2\" class=\"data row10 col2\" >5144363585603.9170</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row10_col3\" class=\"data row10 col3\" >2260806.5900</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row10_col4\" class=\"data row10 col4\" >0.2928</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row10_col5\" class=\"data row10 col5\" >3.7792</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row10_col6\" class=\"data row10 col6\" >399.5518</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row10_col7\" class=\"data row10 col7\" >0.0440</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cd02590d_d280_11ec_967d_7085c2294e08level0_row11\" class=\"row_heading level0 row11\" >lr</th>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row11_col0\" class=\"data row11 col0\" >Linear Regression</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row11_col1\" class=\"data row11 col1\" >1379223.0500</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row11_col2\" class=\"data row11 col2\" >5167804055552.0000</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row11_col3\" class=\"data row11 col3\" >2268755.4500</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row11_col4\" class=\"data row11 col4\" >0.2766</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row11_col5\" class=\"data row11 col5\" >3.0364</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row11_col6\" class=\"data row11 col6\" >176.5260</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row11_col7\" class=\"data row11 col7\" >1.1720</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cd02590d_d280_11ec_967d_7085c2294e08level0_row12\" class=\"row_heading level0 row12\" >omp</th>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row12_col0\" class=\"data row12 col0\" >Orthogonal Matching Pursuit</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row12_col1\" class=\"data row12 col1\" >1206133.4257</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row12_col2\" class=\"data row12 col2\" >5286169007707.4590</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row12_col3\" class=\"data row12 col3\" >2260383.6586</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row12_col4\" class=\"data row12 col4\" >0.2672</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row12_col5\" class=\"data row12 col5\" >2.5499</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row12_col6\" class=\"data row12 col6\" >88.5197</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row12_col7\" class=\"data row12 col7\" >0.0080</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cd02590d_d280_11ec_967d_7085c2294e08level0_row13\" class=\"row_heading level0 row13\" >lasso</th>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row13_col0\" class=\"data row13 col0\" >Lasso Regression</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row13_col1\" class=\"data row13 col1\" >1331769.5250</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row13_col2\" class=\"data row13 col2\" >5735291971174.4004</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row13_col3\" class=\"data row13 col3\" >2379944.2250</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row13_col4\" class=\"data row13 col4\" >0.1871</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row13_col5\" class=\"data row13 col5\" >2.9146</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row13_col6\" class=\"data row13 col6\" >177.7356</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row13_col7\" class=\"data row13 col7\" >0.0220</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cd02590d_d280_11ec_967d_7085c2294e08level0_row14\" class=\"row_heading level0 row14\" >knn</th>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row14_col0\" class=\"data row14 col0\" >K Neighbors Regressor</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row14_col1\" class=\"data row14 col1\" >1251796.4375</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row14_col2\" class=\"data row14 col2\" >5908596837580.7998</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row14_col3\" class=\"data row14 col3\" >2387795.4250</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row14_col4\" class=\"data row14 col4\" >0.2283</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row14_col5\" class=\"data row14 col5\" >1.8132</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row14_col6\" class=\"data row14 col6\" >24.5819</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row14_col7\" class=\"data row14 col7\" >0.0160</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cd02590d_d280_11ec_967d_7085c2294e08level0_row15\" class=\"row_heading level0 row15\" >llar</th>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row15_col0\" class=\"data row15 col0\" >Lasso Least Angle Regression</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row15_col1\" class=\"data row15 col1\" >1345177.6254</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row15_col2\" class=\"data row15 col2\" >5949599780914.5176</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row15_col3\" class=\"data row15 col3\" >2419735.4839</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row15_col4\" class=\"data row15 col4\" >0.1538</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row15_col5\" class=\"data row15 col5\" >2.9331</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row15_col6\" class=\"data row15 col6\" >179.0336</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row15_col7\" class=\"data row15 col7\" >0.0160</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cd02590d_d280_11ec_967d_7085c2294e08level0_row16\" class=\"row_heading level0 row16\" >dt</th>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row16_col0\" class=\"data row16 col0\" >Decision Tree Regressor</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row16_col1\" class=\"data row16 col1\" >1211074.8782</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row16_col2\" class=\"data row16 col2\" >6212485749654.9521</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row16_col3\" class=\"data row16 col3\" >2480129.6696</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row16_col4\" class=\"data row16 col4\" >0.1472</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row16_col5\" class=\"data row16 col5\" >1.8766</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row16_col6\" class=\"data row16 col6\" >10.5540</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row16_col7\" class=\"data row16 col7\" >0.0100</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cd02590d_d280_11ec_967d_7085c2294e08level0_row17\" class=\"row_heading level0 row17\" >dummy</th>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row17_col0\" class=\"data row17 col0\" >Dummy Regressor</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row17_col1\" class=\"data row17 col1\" >1760745.3250</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row17_col2\" class=\"data row17 col2\" >7490637922304.0000</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row17_col3\" class=\"data row17 col3\" >2718099.3500</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row17_col4\" class=\"data row17 col4\" >-0.0080</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row17_col5\" class=\"data row17 col5\" >3.8344</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row17_col6\" class=\"data row17 col6\" >473.5532</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row17_col7\" class=\"data row17 col7\" >0.0060</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cd02590d_d280_11ec_967d_7085c2294e08level0_row18\" class=\"row_heading level0 row18\" >par</th>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row18_col0\" class=\"data row18 col0\" >Passive Aggressive Regressor</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row18_col1\" class=\"data row18 col1\" >2070661.0046</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row18_col2\" class=\"data row18 col2\" >19967742871650.2578</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row18_col3\" class=\"data row18 col3\" >4325896.1570</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row18_col4\" class=\"data row18 col4\" >-1.8871</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row18_col5\" class=\"data row18 col5\" >2.5663</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row18_col6\" class=\"data row18 col6\" >36.1702</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row18_col7\" class=\"data row18 col7\" >0.0100</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cd02590d_d280_11ec_967d_7085c2294e08level0_row19\" class=\"row_heading level0 row19\" >lar</th>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row19_col0\" class=\"data row19 col0\" >Least Angle Regression</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row19_col1\" class=\"data row19 col1\" >805749704185780.0000</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row19_col2\" class=\"data row19 col2\" >12006693421487372323397048467456.0000</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row19_col3\" class=\"data row19 col3\" >1657181683730842.5000</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row19_col4\" class=\"data row19 col4\" >-1924813196842150656.0000</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row19_col5\" class=\"data row19 col5\" >12.3775</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row19_col6\" class=\"data row19 col6\" >20214263612.9542</td>\n",
       "                        <td id=\"T_cd02590d_d280_11ec_967d_7085c2294e08row19_col7\" class=\"data row19 col7\" >0.0180</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x15a7b5d0df0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "top10 = compare_models(sort='MSE', n_select=10, fold=5) \n",
    "# 모델들을 비교하여 가장 좋은 순으로 보여줌\n",
    "# sort를 accuracy보다 F1으로 하는것이 더 좋은 f1score랑 accuracy를 낳음,fold 10번하는게 정확도가 올라감"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_d8a842f5_d280_11ec_bebf_7085c2294e08row5_col0,#T_d8a842f5_d280_11ec_bebf_7085c2294e08row5_col1,#T_d8a842f5_d280_11ec_bebf_7085c2294e08row5_col2,#T_d8a842f5_d280_11ec_bebf_7085c2294e08row5_col3,#T_d8a842f5_d280_11ec_bebf_7085c2294e08row5_col4,#T_d8a842f5_d280_11ec_bebf_7085c2294e08row5_col5{\n",
       "            background:  yellow;\n",
       "        }</style><table id=\"T_d8a842f5_d280_11ec_bebf_7085c2294e08\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >MAE</th>        <th class=\"col_heading level0 col1\" >MSE</th>        <th class=\"col_heading level0 col2\" >RMSE</th>        <th class=\"col_heading level0 col3\" >R2</th>        <th class=\"col_heading level0 col4\" >RMSLE</th>        <th class=\"col_heading level0 col5\" >MAPE</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_d8a842f5_d280_11ec_bebf_7085c2294e08level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_d8a842f5_d280_11ec_bebf_7085c2294e08row0_col0\" class=\"data row0 col0\" >1042981.4233</td>\n",
       "                        <td id=\"T_d8a842f5_d280_11ec_bebf_7085c2294e08row0_col1\" class=\"data row0 col1\" >3243314757101.7168</td>\n",
       "                        <td id=\"T_d8a842f5_d280_11ec_bebf_7085c2294e08row0_col2\" class=\"data row0 col2\" >1800920.5305</td>\n",
       "                        <td id=\"T_d8a842f5_d280_11ec_bebf_7085c2294e08row0_col3\" class=\"data row0 col3\" >0.4284</td>\n",
       "                        <td id=\"T_d8a842f5_d280_11ec_bebf_7085c2294e08row0_col4\" class=\"data row0 col4\" >3.1528</td>\n",
       "                        <td id=\"T_d8a842f5_d280_11ec_bebf_7085c2294e08row0_col5\" class=\"data row0 col5\" >134.8512</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_d8a842f5_d280_11ec_bebf_7085c2294e08level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_d8a842f5_d280_11ec_bebf_7085c2294e08row1_col0\" class=\"data row1 col0\" >1246989.2849</td>\n",
       "                        <td id=\"T_d8a842f5_d280_11ec_bebf_7085c2294e08row1_col1\" class=\"data row1 col1\" >6051297662771.0762</td>\n",
       "                        <td id=\"T_d8a842f5_d280_11ec_bebf_7085c2294e08row1_col2\" class=\"data row1 col2\" >2459938.5486</td>\n",
       "                        <td id=\"T_d8a842f5_d280_11ec_bebf_7085c2294e08row1_col3\" class=\"data row1 col3\" >0.3653</td>\n",
       "                        <td id=\"T_d8a842f5_d280_11ec_bebf_7085c2294e08row1_col4\" class=\"data row1 col4\" >2.4276</td>\n",
       "                        <td id=\"T_d8a842f5_d280_11ec_bebf_7085c2294e08row1_col5\" class=\"data row1 col5\" >48.0542</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_d8a842f5_d280_11ec_bebf_7085c2294e08level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_d8a842f5_d280_11ec_bebf_7085c2294e08row2_col0\" class=\"data row2 col0\" >1280371.8127</td>\n",
       "                        <td id=\"T_d8a842f5_d280_11ec_bebf_7085c2294e08row2_col1\" class=\"data row2 col1\" >3687975400157.4897</td>\n",
       "                        <td id=\"T_d8a842f5_d280_11ec_bebf_7085c2294e08row2_col2\" class=\"data row2 col2\" >1920410.2166</td>\n",
       "                        <td id=\"T_d8a842f5_d280_11ec_bebf_7085c2294e08row2_col3\" class=\"data row2 col3\" >0.3860</td>\n",
       "                        <td id=\"T_d8a842f5_d280_11ec_bebf_7085c2294e08row2_col4\" class=\"data row2 col4\" >2.7943</td>\n",
       "                        <td id=\"T_d8a842f5_d280_11ec_bebf_7085c2294e08row2_col5\" class=\"data row2 col5\" >90.7361</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_d8a842f5_d280_11ec_bebf_7085c2294e08level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_d8a842f5_d280_11ec_bebf_7085c2294e08row3_col0\" class=\"data row3 col0\" >1169077.7906</td>\n",
       "                        <td id=\"T_d8a842f5_d280_11ec_bebf_7085c2294e08row3_col1\" class=\"data row3 col1\" >2847938183095.9976</td>\n",
       "                        <td id=\"T_d8a842f5_d280_11ec_bebf_7085c2294e08row3_col2\" class=\"data row3 col2\" >1687583.5337</td>\n",
       "                        <td id=\"T_d8a842f5_d280_11ec_bebf_7085c2294e08row3_col3\" class=\"data row3 col3\" >0.5436</td>\n",
       "                        <td id=\"T_d8a842f5_d280_11ec_bebf_7085c2294e08row3_col4\" class=\"data row3 col4\" >2.7329</td>\n",
       "                        <td id=\"T_d8a842f5_d280_11ec_bebf_7085c2294e08row3_col5\" class=\"data row3 col5\" >102.6595</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_d8a842f5_d280_11ec_bebf_7085c2294e08level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_d8a842f5_d280_11ec_bebf_7085c2294e08row4_col0\" class=\"data row4 col0\" >1322759.9543</td>\n",
       "                        <td id=\"T_d8a842f5_d280_11ec_bebf_7085c2294e08row4_col1\" class=\"data row4 col1\" >5711918615627.0303</td>\n",
       "                        <td id=\"T_d8a842f5_d280_11ec_bebf_7085c2294e08row4_col2\" class=\"data row4 col2\" >2389962.0532</td>\n",
       "                        <td id=\"T_d8a842f5_d280_11ec_bebf_7085c2294e08row4_col3\" class=\"data row4 col3\" >0.4142</td>\n",
       "                        <td id=\"T_d8a842f5_d280_11ec_bebf_7085c2294e08row4_col4\" class=\"data row4 col4\" >2.8733</td>\n",
       "                        <td id=\"T_d8a842f5_d280_11ec_bebf_7085c2294e08row4_col5\" class=\"data row4 col5\" >94.5302</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_d8a842f5_d280_11ec_bebf_7085c2294e08level0_row5\" class=\"row_heading level0 row5\" >Mean</th>\n",
       "                        <td id=\"T_d8a842f5_d280_11ec_bebf_7085c2294e08row5_col0\" class=\"data row5 col0\" >1212436.0531</td>\n",
       "                        <td id=\"T_d8a842f5_d280_11ec_bebf_7085c2294e08row5_col1\" class=\"data row5 col1\" >4308488923750.6626</td>\n",
       "                        <td id=\"T_d8a842f5_d280_11ec_bebf_7085c2294e08row5_col2\" class=\"data row5 col2\" >2051762.9765</td>\n",
       "                        <td id=\"T_d8a842f5_d280_11ec_bebf_7085c2294e08row5_col3\" class=\"data row5 col3\" >0.4275</td>\n",
       "                        <td id=\"T_d8a842f5_d280_11ec_bebf_7085c2294e08row5_col4\" class=\"data row5 col4\" >2.7962</td>\n",
       "                        <td id=\"T_d8a842f5_d280_11ec_bebf_7085c2294e08row5_col5\" class=\"data row5 col5\" >94.1662</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_d8a842f5_d280_11ec_bebf_7085c2294e08level0_row6\" class=\"row_heading level0 row6\" >SD</th>\n",
       "                        <td id=\"T_d8a842f5_d280_11ec_bebf_7085c2294e08row6_col0\" class=\"data row6 col0\" >98565.0718</td>\n",
       "                        <td id=\"T_d8a842f5_d280_11ec_bebf_7085c2294e08row6_col1\" class=\"data row6 col1\" >1316042454112.4272</td>\n",
       "                        <td id=\"T_d8a842f5_d280_11ec_bebf_7085c2294e08row6_col2\" class=\"data row6 col2\" >314257.2386</td>\n",
       "                        <td id=\"T_d8a842f5_d280_11ec_bebf_7085c2294e08row6_col3\" class=\"data row6 col3\" >0.0620</td>\n",
       "                        <td id=\"T_d8a842f5_d280_11ec_bebf_7085c2294e08row6_col4\" class=\"data row6 col4\" >0.2336</td>\n",
       "                        <td id=\"T_d8a842f5_d280_11ec_bebf_7085c2294e08row6_col5\" class=\"data row6 col5\" >27.8051</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x15a7d1c8e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tuned_top5 = [tune_model(i, fold=5) for i in top10[:5]]\n",
    "# 상위 4개, 5개로 했을 때 제일 좋은 결과가 나옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_dbebf5d2_d280_11ec_a261_7085c2294e08row10_col0,#T_dbebf5d2_d280_11ec_a261_7085c2294e08row10_col1,#T_dbebf5d2_d280_11ec_a261_7085c2294e08row10_col2,#T_dbebf5d2_d280_11ec_a261_7085c2294e08row10_col3,#T_dbebf5d2_d280_11ec_a261_7085c2294e08row10_col4,#T_dbebf5d2_d280_11ec_a261_7085c2294e08row10_col5{\n",
       "            background:  yellow;\n",
       "        }</style><table id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >MAE</th>        <th class=\"col_heading level0 col1\" >MSE</th>        <th class=\"col_heading level0 col2\" >RMSE</th>        <th class=\"col_heading level0 col3\" >R2</th>        <th class=\"col_heading level0 col4\" >RMSLE</th>        <th class=\"col_heading level0 col5\" >MAPE</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08row0_col0\" class=\"data row0 col0\" >902725.5513</td>\n",
       "                        <td id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08row0_col1\" class=\"data row0 col1\" >3105301883120.2051</td>\n",
       "                        <td id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08row0_col2\" class=\"data row0 col2\" >1762186.6766</td>\n",
       "                        <td id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08row0_col3\" class=\"data row0 col3\" >0.5468</td>\n",
       "                        <td id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08row0_col4\" class=\"data row0 col4\" >2.9945</td>\n",
       "                        <td id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08row0_col5\" class=\"data row0 col5\" >108.6820</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08row1_col0\" class=\"data row1 col0\" >857912.1702</td>\n",
       "                        <td id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08row1_col1\" class=\"data row1 col1\" >2027133371388.0437</td>\n",
       "                        <td id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08row1_col2\" class=\"data row1 col2\" >1423774.3401</td>\n",
       "                        <td id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08row1_col3\" class=\"data row1 col3\" >0.5340</td>\n",
       "                        <td id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08row1_col4\" class=\"data row1 col4\" >2.9369</td>\n",
       "                        <td id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08row1_col5\" class=\"data row1 col5\" >110.3349</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08row2_col0\" class=\"data row2 col0\" >1427364.5372</td>\n",
       "                        <td id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08row2_col1\" class=\"data row2 col1\" >7471688395564.9756</td>\n",
       "                        <td id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08row2_col2\" class=\"data row2 col2\" >2733438.9321</td>\n",
       "                        <td id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08row2_col3\" class=\"data row2 col3\" >0.3964</td>\n",
       "                        <td id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08row2_col4\" class=\"data row2 col4\" >2.3146</td>\n",
       "                        <td id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08row2_col5\" class=\"data row2 col5\" >35.4312</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08row3_col0\" class=\"data row3 col0\" >906692.0843</td>\n",
       "                        <td id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08row3_col1\" class=\"data row3 col1\" >4234406081168.2974</td>\n",
       "                        <td id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08row3_col2\" class=\"data row3 col2\" >2057767.2563</td>\n",
       "                        <td id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08row3_col3\" class=\"data row3 col3\" >0.3517</td>\n",
       "                        <td id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08row3_col4\" class=\"data row3 col4\" >1.9459</td>\n",
       "                        <td id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08row3_col5\" class=\"data row3 col5\" >28.8599</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08row4_col0\" class=\"data row4 col0\" >1298013.8242</td>\n",
       "                        <td id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08row4_col1\" class=\"data row4 col1\" >3563592583029.1216</td>\n",
       "                        <td id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08row4_col2\" class=\"data row4 col2\" >1887748.0189</td>\n",
       "                        <td id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08row4_col3\" class=\"data row4 col3\" >0.0561</td>\n",
       "                        <td id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08row4_col4\" class=\"data row4 col4\" >2.6839</td>\n",
       "                        <td id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08row4_col5\" class=\"data row4 col5\" >37.7465</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08row5_col0\" class=\"data row5 col0\" >1126500.7199</td>\n",
       "                        <td id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08row5_col1\" class=\"data row5 col1\" >3750484288760.0688</td>\n",
       "                        <td id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08row5_col2\" class=\"data row5 col2\" >1936616.7119</td>\n",
       "                        <td id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08row5_col3\" class=\"data row5 col3\" >0.5395</td>\n",
       "                        <td id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08row5_col4\" class=\"data row5 col4\" >2.1663</td>\n",
       "                        <td id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08row5_col5\" class=\"data row5 col5\" >28.6519</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "                        <td id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08row6_col0\" class=\"data row6 col0\" >1200414.5720</td>\n",
       "                        <td id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08row6_col1\" class=\"data row6 col1\" >3270460442686.2231</td>\n",
       "                        <td id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08row6_col2\" class=\"data row6 col2\" >1808441.4402</td>\n",
       "                        <td id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08row6_col3\" class=\"data row6 col3\" >0.4343</td>\n",
       "                        <td id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08row6_col4\" class=\"data row6 col4\" >2.9854</td>\n",
       "                        <td id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08row6_col5\" class=\"data row6 col5\" >127.5270</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "                        <td id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08row7_col0\" class=\"data row7 col0\" >1170258.6455</td>\n",
       "                        <td id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08row7_col1\" class=\"data row7 col1\" >2804157698189.4487</td>\n",
       "                        <td id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08row7_col2\" class=\"data row7 col2\" >1674561.9422</td>\n",
       "                        <td id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08row7_col3\" class=\"data row7 col3\" >0.5795</td>\n",
       "                        <td id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08row7_col4\" class=\"data row7 col4\" >2.4454</td>\n",
       "                        <td id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08row7_col5\" class=\"data row7 col5\" >65.7985</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "                        <td id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08row8_col0\" class=\"data row8 col0\" >806061.4059</td>\n",
       "                        <td id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08row8_col1\" class=\"data row8 col1\" >2653789879857.4292</td>\n",
       "                        <td id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08row8_col2\" class=\"data row8 col2\" >1629045.6961</td>\n",
       "                        <td id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08row8_col3\" class=\"data row8 col3\" >0.6770</td>\n",
       "                        <td id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08row8_col4\" class=\"data row8 col4\" >3.3918</td>\n",
       "                        <td id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08row8_col5\" class=\"data row8 col5\" >134.2762</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "                        <td id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08row9_col0\" class=\"data row9 col0\" >1652453.5633</td>\n",
       "                        <td id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08row9_col1\" class=\"data row9 col1\" >8269760545037.5859</td>\n",
       "                        <td id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08row9_col2\" class=\"data row9 col2\" >2875719.1353</td>\n",
       "                        <td id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08row9_col3\" class=\"data row9 col3\" >0.2564</td>\n",
       "                        <td id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08row9_col4\" class=\"data row9 col4\" >2.2313</td>\n",
       "                        <td id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08row9_col5\" class=\"data row9 col5\" >21.8226</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08level0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n",
       "                        <td id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08row10_col0\" class=\"data row10 col0\" >1134839.7074</td>\n",
       "                        <td id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08row10_col1\" class=\"data row10 col1\" >4115077516880.1401</td>\n",
       "                        <td id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08row10_col2\" class=\"data row10 col2\" >1978930.0150</td>\n",
       "                        <td id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08row10_col3\" class=\"data row10 col3\" >0.4372</td>\n",
       "                        <td id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08row10_col4\" class=\"data row10 col4\" >2.6096</td>\n",
       "                        <td id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08row10_col5\" class=\"data row10 col5\" >69.9131</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08level0_row11\" class=\"row_heading level0 row11\" >SD</th>\n",
       "                        <td id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08row11_col0\" class=\"data row11 col0\" >260087.8941</td>\n",
       "                        <td id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08row11_col1\" class=\"data row11 col1\" >1972965755715.9221</td>\n",
       "                        <td id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08row11_col2\" class=\"data row11 col2\" >445997.2116</td>\n",
       "                        <td id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08row11_col3\" class=\"data row11 col3\" >0.1722</td>\n",
       "                        <td id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08row11_col4\" class=\"data row11 col4\" >0.4368</td>\n",
       "                        <td id=\"T_dbebf5d2_d280_11ec_a261_7085c2294e08row11_col5\" class=\"data row11 col5\" >43.0582</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x15a7bd49ee0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "blender_top5 = blend_models(estimator_list=tuned_top5) #보팅(voting)해줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_model = finalize_model(blender_top5)\n",
    "prediction = predict_model(final_model, data=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction['Target'] = prediction['Target'].astype(int)\n",
    "prediction['Label'] = prediction['Label'].astype(float)\n",
    "prediction['Label'] = prediction['Label'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2085797.8923"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pycaret.utils import check_metric\n",
    "check_metric(prediction['Target'], prediction['Label'], metric = 'RMSE') # 정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4350552847704.8447"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# F1score\n",
    "check_metric(prediction['Target'], prediction['Label'], metric = 'MSE') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-fold 및 보팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "from ngboost import NGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits =  10, shuffle = True, random_state = 100) # fold 10번하기\n",
    "\n",
    "lgbm = LGBMRegressor(random_state = 518)\n",
    "acc_list = []\n",
    "lgbm_pred = np.zeros((y_test.shape[0]))\n",
    "for tr_idx, val_idx in kf.split(X_train, y_train) :\n",
    "    tr_x, tr_y = X_train.iloc[tr_idx], y_train.iloc[tr_idx]\n",
    "    val_x, val_y = X_train.iloc[val_idx], y_train.iloc[val_idx]\n",
    "    \n",
    "    lgbm.fit(tr_x, tr_y)\n",
    "    \n",
    "    pred = lgbm.predict(val_x)\n",
    "    sub_pred = lgbm.predict(X_test)\n",
    "    RMSE = np.sqrt(mean_squared_error(lr_pred, y_test))\n",
    "    \n",
    "    acc_list.append(RMSE)\n",
    "    \n",
    "    lgbm_pred += (sub_pred / 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic regression acc 2116782.6724485313\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print('logistic regression acc',np.sqrt(mean_squared_error(lgbm_pred, y_test))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits =  10, shuffle = True, random_state = 100) # fold 10번하기\n",
    "\n",
    "gbm = GradientBoostingRegressor(random_state = 42)\n",
    "acc_list = []\n",
    "gbm_pred = np.zeros((y_test.shape[0]))\n",
    "for tr_idx, val_idx in kf.split(X_train, y_train) :\n",
    "    tr_x, tr_y = X_train.iloc[tr_idx], y_train.iloc[tr_idx]\n",
    "    val_x, val_y = X_train.iloc[val_idx], y_train.iloc[val_idx]\n",
    "    \n",
    "    gbm.fit(tr_x, tr_y)\n",
    "    \n",
    "    pred = gbm.predict(val_x)\n",
    "    sub_pred = gbm.predict(X_test)\n",
    "    RMSE = np.sqrt(mean_squared_error(gbm_pred, y_test))\n",
    "    \n",
    "    acc_list.append(RMSE)\n",
    "    \n",
    "    gbm_pred += (sub_pred / 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm acc 2237619.653127805\n"
     ]
    }
   ],
   "source": [
    "print('gbm acc',np.sqrt(mean_squared_error(gbm_pred, y_test))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 0] loss=16.1278 val_loss=0.0000 scale=1.0000 norm=1564488.2358\n",
      "[iter 100] loss=15.1138 val_loss=0.0000 scale=2.0000 norm=1268465.2202\n",
      "[iter 200] loss=14.5442 val_loss=0.0000 scale=2.0000 norm=925846.8043\n",
      "[iter 300] loss=14.1659 val_loss=0.0000 scale=1.0000 norm=390652.9993\n",
      "[iter 400] loss=13.9441 val_loss=0.0000 scale=1.0000 norm=360362.2545\n",
      "[iter 0] loss=14.1835 val_loss=0.0000 scale=1.0000 norm=401193.9737\n",
      "[iter 100] loss=13.8480 val_loss=0.0000 scale=1.0000 norm=362198.5891\n",
      "[iter 200] loss=13.7800 val_loss=0.0000 scale=0.5000 norm=172982.7553\n",
      "[iter 300] loss=13.7504 val_loss=0.0000 scale=0.1250 norm=42204.3902\n",
      "[iter 400] loss=13.7438 val_loss=0.0000 scale=0.0312 norm=10454.6373\n",
      "[iter 0] loss=14.2350 val_loss=0.0000 scale=0.5000 norm=171129.9662\n",
      "[iter 100] loss=13.7845 val_loss=0.0000 scale=0.0312 norm=9945.4926\n",
      "[iter 200] loss=13.7540 val_loss=0.0000 scale=0.0000 norm=0.0003\n",
      "[iter 300] loss=13.7540 val_loss=0.0000 scale=0.0000 norm=0.0003\n",
      "[iter 400] loss=13.7540 val_loss=0.0000 scale=0.0000 norm=0.0003\n",
      "[iter 0] loss=13.7600 val_loss=0.0000 scale=1.0000 norm=323094.3688\n",
      "[iter 100] loss=13.6864 val_loss=0.0000 scale=0.2500 norm=76057.0638\n",
      "[iter 200] loss=13.6297 val_loss=0.0000 scale=0.2500 norm=73138.9418\n",
      "[iter 300] loss=13.6052 val_loss=0.0000 scale=0.0000 norm=0.0003\n",
      "[iter 400] loss=13.6052 val_loss=0.0000 scale=0.0000 norm=0.0003\n",
      "[iter 0] loss=13.6270 val_loss=0.0000 scale=1.0000 norm=293700.3806\n",
      "[iter 100] loss=13.5640 val_loss=0.0000 scale=0.5000 norm=138693.9441\n",
      "[iter 200] loss=13.5392 val_loss=0.0000 scale=0.0625 norm=16890.1245\n",
      "[iter 300] loss=13.5339 val_loss=0.0000 scale=0.0156 norm=4192.0030\n",
      "[iter 400] loss=13.5319 val_loss=0.0000 scale=0.0039 norm=1045.8880\n",
      "[iter 0] loss=13.7296 val_loss=0.0000 scale=1.0000 norm=275894.6281\n",
      "[iter 100] loss=13.4910 val_loss=0.0000 scale=0.5000 norm=127928.3090\n",
      "[iter 200] loss=13.4303 val_loss=0.0000 scale=0.5000 norm=122297.8230\n",
      "[iter 300] loss=13.4015 val_loss=0.0000 scale=0.5000 norm=119282.5641\n",
      "[iter 400] loss=13.3908 val_loss=0.0000 scale=0.1250 norm=29453.0431\n",
      "[iter 0] loss=20.0432 val_loss=0.0000 scale=1.0000 norm=260988.1347\n",
      "[iter 100] loss=13.5776 val_loss=0.0000 scale=1.0000 norm=223796.5176\n",
      "[iter 200] loss=13.4721 val_loss=0.0000 scale=0.2500 norm=53344.0925\n",
      "[iter 300] loss=13.4068 val_loss=0.0000 scale=0.0312 norm=6455.8526\n",
      "[iter 400] loss=13.3840 val_loss=0.0000 scale=0.0000 norm=0.0004\n",
      "[iter 0] loss=13.5962 val_loss=0.0000 scale=1.0000 norm=232909.2181\n",
      "[iter 100] loss=13.3990 val_loss=0.0000 scale=1.0000 norm=213404.3066\n",
      "[iter 200] loss=13.3328 val_loss=0.0000 scale=1.0000 norm=205510.0581\n",
      "[iter 300] loss=13.2978 val_loss=0.0000 scale=1.0000 norm=201035.7772\n",
      "[iter 400] loss=13.2925 val_loss=0.0000 scale=0.0000 norm=0.0004\n",
      "[iter 0] loss=13.3155 val_loss=0.0000 scale=0.5000 norm=100271.0844\n",
      "[iter 100] loss=13.2979 val_loss=0.0000 scale=0.0000 norm=0.0004\n",
      "[iter 200] loss=13.2979 val_loss=0.0000 scale=0.0000 norm=0.0004\n",
      "[iter 300] loss=13.2979 val_loss=0.0000 scale=0.0000 norm=0.0004\n",
      "[iter 400] loss=13.2979 val_loss=0.0000 scale=0.0000 norm=0.0004\n",
      "[iter 0] loss=13.5250 val_loss=0.0000 scale=1.0000 norm=202614.1374\n",
      "[iter 100] loss=13.2925 val_loss=0.0000 scale=0.2500 norm=48122.9246\n",
      "[iter 200] loss=13.2527 val_loss=0.0000 scale=0.1250 norm=23439.2929\n",
      "[iter 300] loss=13.2187 val_loss=0.0000 scale=0.2500 norm=45797.3289\n",
      "[iter 400] loss=13.1953 val_loss=0.0000 scale=0.5000 norm=89977.3879\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits =  10, shuffle = True, random_state = 100) # fold 10번하기\n",
    "\n",
    "ngb = NGBRegressor(random_state = 518)\n",
    "\n",
    "acc_list = []\n",
    "ngb_pred = np.zeros((y_test.shape[0]))\n",
    "for tr_idx, val_idx in kf.split(X_train, y_train) :\n",
    "    tr_x, tr_y = X_train.iloc[tr_idx], y_train.iloc[tr_idx]\n",
    "    val_x, val_y = X_train.iloc[val_idx], y_train.iloc[val_idx]\n",
    "    \n",
    "    ngb.fit(tr_x, tr_y)\n",
    "    \n",
    "    pred = ngb.predict(val_x)\n",
    "    sub_pred = ngb.predict(X_test)\n",
    "    RMSE = np.sqrt(mean_squared_error(gbm_pred, y_test))\n",
    "    \n",
    "    acc_list.append(RMSE)\n",
    "    \n",
    "    ngb_pred += (sub_pred / 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ngb acc 2398060.8733508103\n"
     ]
    }
   ],
   "source": [
    "print('ngb acc',np.sqrt(mean_squared_error(ngb_pred, y_test))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits =  10, shuffle = True, random_state = 100) # fold 10번하기\n",
    "rf = RandomForestRegressor(random_state = 518)\n",
    "\n",
    "acc_list = []\n",
    "rf_pred = np.zeros((y_test.shape[0]))\n",
    "for tr_idx, val_idx in kf.split(X_train, y_train) :\n",
    "    tr_x, tr_y = X_train.iloc[tr_idx], y_train.iloc[tr_idx]\n",
    "    val_x, val_y = X_train.iloc[val_idx], y_train.iloc[val_idx]\n",
    "    \n",
    "    rf.fit(tr_x, tr_y)\n",
    "    \n",
    "    pred = rf.predict(val_x)\n",
    "    sub_pred = rf.predict(X_test)\n",
    "    RMSE = np.sqrt(mean_squared_error(rf_pred, y_test))\n",
    "    \n",
    "    acc_list.append(RMSE)\n",
    "    \n",
    "    rf_pred += (sub_pred / 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf acc 2225151.3099162993\n"
     ]
    }
   ],
   "source": [
    "print('rf acc',np.sqrt(mean_squared_error(rf_pred, y_test))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits =  10, shuffle = True, random_state = 100) # fold 10번하기\n",
    "\n",
    "cat = CatBoostRegressor(random_state = 518, silent = True)\n",
    "\n",
    "acc_list = []\n",
    "cat_pred = np.zeros((y_test.shape[0]))\n",
    "for tr_idx, val_idx in kf.split(X_train, y_train) :\n",
    "    tr_x, tr_y = X_train.iloc[tr_idx], y_train.iloc[tr_idx]\n",
    "    val_x, val_y = X_train.iloc[val_idx], y_train.iloc[val_idx]\n",
    "    \n",
    "    cat.fit(tr_x, tr_y)\n",
    "    \n",
    "    pred = cat.predict(val_x)\n",
    "    sub_pred = cat.predict(X_test)\n",
    "    RMSE = np.sqrt(mean_squared_error(cat_pred, y_test))\n",
    "    \n",
    "    acc_list.append(RMSE)\n",
    "    \n",
    "    cat_pred += (sub_pred / 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat acc 2205251.5155068124\n"
     ]
    }
   ],
   "source": [
    "print('cat acc',np.sqrt(mean_squared_error(cat_pred, y_test))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 보팅"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "보팅 (Voting): 투표를 통해 결과 도출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold_vote = (lgbm_pred+ngb_pred+gbm_pred+rf_pred+cat_pred)/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ngb acc 2209799.0540659814\n"
     ]
    }
   ],
   "source": [
    "print('ngb acc',np.sqrt(mean_squared_error(kfold_vote, y_test))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정규화 전  정확도, f1score\n",
    "rc_pred+lr_pred+lda_pred+py_pred\n",
    "- 모든 피처(스크린수 포함) 0.8034, 0.4848\n",
    "  - 모든 피처를 사용하면 가장 좋은 정확도를 보여줌\n",
    "- screen 제외 0.7745, 0.4179\n",
    "  - screen 수를 제외하면 0.03 정도의 정확도가 떨어지고 0.066정도의 성능이 떨어짐\n",
    "- screen& act_n 제외 0.7976, 0.4615 # 정규화 안해주는게 더 좋은 결과를 보여줌\n",
    "  - 모든 피처중 act_n를 제외하는 것이 가장 좋은 결과를 보여줌\n",
    "- screen& genre 제외 0.7687, 0.3933\n",
    "  - 장르를 제외하면 0.035 정도의 정확도가 떨어트리고 0.085정도의 성능이 떨어짐\n",
    "- screen& direct 제외 0.7630, 0.4383\n",
    "  - 감독을 제외하면 0.04정도 정확도가 떨어지고 0.046정도의 성능이 떨어짐\n",
    "- screen& dist 제외 0.7745, 0.3999\n",
    "   - 배급사를 제외하면 0.03 정도의 정확도가 떨어지고 0.085정도의 성능이 떨어짐\n",
    "- screen& 네이버 기대지수 제외 0.7803, 0.4242\n",
    "   - 네이버 기대지수를 제외하면 0.0231 정도의 정확도가 떨어지고, 0.06정도의 성능이 떨어짐 \n",
    "- screen& star buzz 제외 0.7803, 0.4242\n",
    "   - star buzz를 제외하면 0.0231 정도의 정확도가 떨어지고, 0.06정도의 성능이 떨어짐 \n",
    "- screen& 네이버 movie buzz 제외 0.7630, 0.2807\n",
    "   - 네이버 movie buzz를 제외하면 0.04 정도의 정확도가 떨어지고, 0.204정도의 성능이 떨어짐 \n",
    "- screen& 구글 트렌드 제외 0.7803, 0.4242\n",
    "   - 구글 movie buzz를 제외하면 0.0231 정도의 정확도가 떨어지고, 0.06정도의 성능이 떨어짐 \n",
    "\n",
    "정규화 후\n",
    "rc_pred+lr_pred+lda_pred+py_pred\n",
    "- screen& act_n 제외 - 0.7919, 0.4375  # 정규화 안해주는게 더 좋은 결과를 보여줌"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정리하면\n",
    "- 네이버 movie buzz가 가장 중요한 피처라고 할 수 있음\n",
    "- 장르, 배급사, 스크린 수, 네이버 기대지수와 스타버즈, 구글트렌드 순으로 중요하고, 네이버 기대지수와 스타버즈, 구글트렌드의 중요도가 똑같다\n",
    "- 네이버 movie buzz를 포함한 다른 sns 요소들이 예측에 의미 있는 피처들인 것을 보여줌"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "보팅 알고리즘 또한 같은 결과를 보여주지만 안쓰는 이유는 에러가 자주나기 때문에 안정적이지 않음\n",
    "## 보팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "vo_clf = VotingClassifier(estimators=[('LR',lr),('LD',lda),('Py',final_model)], voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting 분류기 정확도 0.7687861271676301\n",
      "f1 0.411764705882353\n"
     ]
    }
   ],
   "source": [
    "vo_clf.fit(X_train, y_train)\n",
    "pred = vo_clf.predict(X_test)\n",
    "print(\"Voting 분류기 정확도\", accuracy_score(y_test, pred))\n",
    "print('f1',f1_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acc_list = []\n",
    "f1_list = []\n",
    "vo_pred = np.zeros((y_test.shape[0]))\n",
    "for tr_idx, val_idx in kf.split(X_train, y_train) :\n",
    "    tr_x, tr_y = X_train.iloc[tr_idx], y_train.iloc[tr_idx]\n",
    "    val_x, val_y = X_train.iloc[val_idx], y_train.iloc[val_idx]\n",
    "    \n",
    "    vo_clf.fit(tr_x, tr_y)\n",
    "    \n",
    "    pred = vo_clf.predict(val_x)\n",
    "    sub_pred = vo_clf.predict(X_test)\n",
    "    acc = accuracy_score(val_y, pred)\n",
    "    f1_list = f1_score(np.round(vo_pred), y_test)\n",
    "    acc_list.append(acc)\n",
    "    \n",
    "    vo_pred += (sub_pred / 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7985365853658537"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(acc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7803468208092486"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(np.round(vo_pred), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42424242424242425"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(np.round(vo_pred), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_models = [\n",
    "    ('LR',lr),('LD',lda),('RC',rc)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_reg = StackingClassifier(stack_models, final_estimator=xgb, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7572254335260116"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_reg.fit(X_train, y_train)\n",
    "stack_pred = stack_reg.predict(X_test)\n",
    "accuracy_score(stack_pred , y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'my_predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-169-3df1d4b471bb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0macc_eval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Stacking Ensemble'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstack_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-165-775237c5bad4>\u001b[0m in \u001b[0;36macc_eval\u001b[1;34m(name_, actual, pred)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mmse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactual\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mmy_predictions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname_\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0my_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmy_predictions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'my_predictions' is not defined"
     ]
    }
   ],
   "source": [
    "acc_eval('Stacking Ensemble', y_test, stack_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def plot_predictions(name_, actual, pred):\n",
    "    df = pd.DataFrame({'actual': y_test, 'prediction': pred})\n",
    "    df = df.sort_values(by='actual').reset_index(drop=True)\n",
    "\n",
    "    plt.figure(figsize=(12, 9))\n",
    "    plt.scatter(df.index, df['prediction'], marker='x', color='r')\n",
    "    plt.scatter(df.index, df['actual'], alpha=0.7, marker='o', color='black')\n",
    "    plt.title(name_, fontsize=15)\n",
    "    plt.legend(['prediction', 'actual'], fontsize=12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_eval(name_, actual, pred):\n",
    "    global predictions\n",
    "    global colors\n",
    "\n",
    "    plot_predictions(name_, actual, pred)\n",
    "\n",
    "    mse = accuracy_score(actual, pred)\n",
    "    my_predictions[name_] = mse\n",
    "\n",
    "    y_value = sorted(my_predictions.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    df = pd.DataFrame(y_value, columns=['model', 'acc'])\n",
    "    print(df)\n",
    "    min_ = df['acc'].min() - 10\n",
    "    max_ = df['acc'].max() + 10\n",
    "    \n",
    "    length = len(df)\n",
    "    \n",
    "    plt.figure(figsize=(10, length))\n",
    "    ax = plt.subplot()\n",
    "    ax.set_yticks(np.arange(len(df)))\n",
    "    ax.set_yticklabels(df['model'], fontsize=15)\n",
    "    bars = ax.barh(np.arange(len(df)), df['acc'])\n",
    "    \n",
    "    for i, v in enumerate(df['acc']):\n",
    "        idx = np.random.choice(len(colors))\n",
    "        bars[i].set_color(colors[idx])\n",
    "        ax.text(v + 2, i, str(round(v, 3)), color='k', fontsize=15, fontweight='bold')\n",
    "        \n",
    "    plt.title('ACC Error', fontsize=18)\n",
    "    plt.xlim(min_, max_)\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
